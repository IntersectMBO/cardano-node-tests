"""Tests for KES period."""

import datetime
import json
import logging
import pathlib as pl
import shutil
import time
import typing as tp

import allure
import pytest
from cardano_clusterlib import clusterlib

from cardano_node_tests.cluster_management import cluster_management
from cardano_node_tests.tests import common
from cardano_node_tests.tests import issues
from cardano_node_tests.tests import kes
from cardano_node_tests.utils import cluster_nodes
from cardano_node_tests.utils import clusterlib_utils
from cardano_node_tests.utils import configuration
from cardano_node_tests.utils import helpers
from cardano_node_tests.utils import http_client
from cardano_node_tests.utils import locking
from cardano_node_tests.utils import logfiles
from cardano_node_tests.utils import temptools
from cardano_node_tests.utils.versions import VERSIONS

LOGGER = logging.getLogger(__name__)

pytestmark = common.SKIPIF_WRONG_ERA

# Slot number where KES expires when using `cluster_kes`
KES_EXPIRE_SLOT = 2100


@pytest.fixture(scope="module")
def short_kes_start_cluster() -> pl.Path:
    """Update *slotsPerKESPeriod* and *maxKESEvolutions*."""
    shared_tmp = temptools.get_pytest_shared_tmp()
    max_kes_evolutions = 10

    # Need to lock because this same fixture can run on several workers in parallel
    with locking.FileLockIfXdist(f"{shared_tmp}/startup_files_short_kes.lock"):
        destdir = shared_tmp / "startup_files_short_kes"
        destdir.mkdir(exist_ok=True)

        # Return existing script if it is already generated by other worker
        destdir_ls = list(destdir.glob("start-cluster*"))
        if destdir_ls:
            return destdir_ls[0]

        startup_files = cluster_nodes.get_cluster_type().cluster_scripts.copy_scripts_files(
            destdir=destdir
        )
        with open(startup_files.genesis_spec, encoding="utf-8") as fp_in:
            genesis_spec = json.load(fp_in)

        # KES needs to be valid at least until the local cluster is fully started.
        # We need to calculate how many slots there is from the start of Shelley epoch
        # until the cluster is fully started.
        genesis_spec["slotsPerKESPeriod"] = int(KES_EXPIRE_SLOT / max_kes_evolutions)
        genesis_spec["maxKESEvolutions"] = max_kes_evolutions

        with open(startup_files.genesis_spec, "w", encoding="utf-8") as fp_out:
            json.dump(genesis_spec, fp_out)

        return startup_files.start_script.parent


@pytest.fixture
def cluster_kes(
    cluster_manager: cluster_management.ClusterManager, short_kes_start_cluster: pl.Path
) -> clusterlib.ClusterLib:
    return cluster_manager.get(
        lock_resources=[cluster_management.Resources.CLUSTER],
        prio=True,
        cleanup=True,
        scriptsdir=short_kes_start_cluster,
    )


def _save_metrics(pool_num: int, temp_template: str) -> None:
    instance_ports = cluster_nodes.get_cluster_type().cluster_scripts.get_instance_ports(
        instance_num=cluster_nodes.get_instance_num()
    )
    port = instance_ports.node_ports[pool_num].prometheus

    response = http_client.get_session().get(f"http://localhost:{port}/metrics", timeout=10)
    assert response, f"Request failed, status code {response.status_code}"

    with open(f"{temp_template}_pool{pool_num}_metrics.txt", "w", encoding="utf-8") as fp_out:
        fp_out.write(response.text.strip())


def _check_block_production(
    cluster_obj: clusterlib.ClusterLib,
    temp_template: str,
    pool_id_dec: str,
    in_epoch: int,
) -> tuple[int, bool]:
    cluster_obj.wait_for_epoch(epoch_no=in_epoch)
    clusterlib_utils.wait_for_epoch_interval(
        cluster_obj=cluster_obj,
        start=common.EPOCH_START_SEC_LEDGER_STATE,
        stop=common.EPOCH_STOP_SEC_LEDGER_STATE,
    )
    epoch = cluster_obj.g_query.get_epoch()

    ledger_state = clusterlib_utils.get_ledger_state(cluster_obj=cluster_obj)

    clusterlib_utils.save_ledger_state(
        cluster_obj=cluster_obj,
        state_name=f"{temp_template}_{epoch}",
        ledger_state=ledger_state,
    )

    # Check if the pool is minting any blocks
    blocks_made = ledger_state["blocksCurrent"] or {}
    is_minting = pool_id_dec in blocks_made

    return epoch, is_minting


class TestKES:
    """Basic tests for KES period."""

    @allure.link(helpers.get_vcs_link())
    # It would be better to use `cluster_nodes.get_cluster_type().uses_shortcut`, but we
    # would need to get a cluster instance first. That would be too expensive in this test,
    # as we are using custom startup scripts.
    @pytest.mark.skipif(
        "_fast" not in configuration.TESTNET_VARIANT,
        reason="Runs only on local cluster with HF shortcut.",
    )
    @pytest.mark.order(5)
    @pytest.mark.long
    def test_expired_kes(
        self,
        cluster_kes: clusterlib.ClusterLib,
        cluster_manager: cluster_management.ClusterManager,
        worker_id: str,
    ):
        """Test expired KES.

        * start local cluster instance configured with short KES period and low number of key
          evolutions, so KES expires soon on all pools
        * refresh opcert on 2 of the 3 pools, so KES doesn't expire on those 2 pools and
          the pools keep minting blocks
        * wait for KES expiration on the selected pool
        * check that the pool with expired KES didn't mint blocks in an epoch that followed after
          KES expiration
        * check KES period info command with an operational certificate with an expired KES
        * check KES period info command with operational certificates with a valid KES
        """
        cluster = cluster_kes
        temp_template = common.get_test_id(cluster)

        expire_slot = KES_EXPIRE_SLOT + 100
        expire_node_name = "pool1"
        expire_pool_num = 1
        expire_pool_name = f"node-{expire_node_name}"
        expire_pool_rec = cluster_manager.cache.addrs_data[expire_pool_name]
        expire_pool_id = cluster.g_stake_pool.get_stake_pool_id(
            expire_pool_rec["cold_key_pair"].vkey_file
        )
        expire_pool_id_dec = helpers.decode_bech32(expire_pool_id)

        # Refresh opcert on all pools except of pool1, so KES doesn't expire on those pools and
        # the pools keep minting blocks.
        refreshed_nodes = [
            f"pool{i}" for i in range(2, len(cluster_management.Resources.ALL_POOLS) + 1)
        ]

        # Use socket of pool2 for this test - once bft1 KES expires, bft1 stops syncing
        cluster_nodes.set_cluster_env(
            instance_num=cluster_nodes.get_instance_num(), socket_file_name="pool2.socket"
        )

        def _save_all_metrics(temp_template: str) -> None:
            for pool_num in range(1, len(cluster_management.Resources.ALL_POOLS) + 1):
                _save_metrics(pool_num=pool_num, temp_template=temp_template)

        def _save_all_period_info(temp_template: str) -> None:
            for pool_num, pool_name in enumerate(cluster_management.Resources.ALL_POOLS, start=1):
                pool_rec = cluster_manager.cache.addrs_data[pool_name]
                cluster.g_query.query_cli(
                    [
                        "kes-period-info",
                        "--op-cert-file",
                        str(pool_rec["pool_operational_cert"]),
                        "--out-file",
                        f"{temp_template}_pool{pool_num}_kes_info.txt",
                    ]
                )

        def _refresh_opcerts() -> dict[str, int]:
            """Refresh opcert on pools that are not supposed to expire."""
            refreshed_nodes_kes_period = {}

            for n in refreshed_nodes:
                refreshed_pool_rec = cluster_manager.cache.addrs_data[f"node-{n}"]
                kes_period = cluster.g_query.get_kes_period()

                refreshed_opcert_file = cluster.g_node.gen_node_operational_cert(
                    node_name=f"{n}_refreshed_opcert",
                    kes_vkey_file=refreshed_pool_rec["kes_key_pair"].vkey_file,
                    cold_skey_file=refreshed_pool_rec["cold_key_pair"].skey_file,
                    cold_counter_file=refreshed_pool_rec["cold_key_pair"].counter_file,
                    kes_period=kes_period,
                )
                shutil.copy(refreshed_opcert_file, refreshed_pool_rec["pool_operational_cert"])
                refreshed_nodes_kes_period[n] = kes_period

            cluster_nodes.restart_all_nodes(delay=5)
            return refreshed_nodes_kes_period

        def _check_kes_period_info(
            refreshed_nodes_kes_period: dict[str, int],
        ) -> list[str]:
            errors = []
            # Check kes-period-info with an operational certificate with KES expired
            kes_info_expired = cluster.g_query.get_kes_period_info(
                opcert_file=expire_pool_rec["pool_operational_cert"]
            )
            with open(f"{temp_template}_kes_period_info_1.json", "w", encoding="utf-8") as out_fp:
                json.dump(kes_info_expired, out_fp, indent=2)
            errors.extend(
                kes.check_kes_period_info_result(
                    cluster_obj=cluster,
                    kes_output=kes_info_expired,
                    expected_scenario=kes.KesScenarios.INVALID_KES_PERIOD,
                    check_id="1",
                    pool_num=expire_pool_num,
                )
            )

            # Check kes-period-info with valid operational certificates
            for idx, n in enumerate(refreshed_nodes):
                refreshed_pool_rec = cluster_manager.cache.addrs_data[f"node-{n}"]
                kes_info_valid = cluster.g_query.get_kes_period_info(
                    opcert_file=refreshed_pool_rec["pool_operational_cert"]
                )
                check_id = str(2 + idx)
                with open(
                    f"{temp_template}_kes_period_info_{check_id}.json", "w", encoding="utf-8"
                ) as out_fp:
                    json.dump(kes_info_valid, out_fp, indent=2)
                errors.extend(
                    kes.check_kes_period_info_result(
                        cluster_obj=cluster,
                        kes_output=kes_info_valid,
                        expected_scenario=kes.KesScenarios.ALL_VALID,
                        check_id=check_id,
                        expected_start_kes=refreshed_nodes_kes_period[n],
                    )
                )

            return errors

        this_epoch = cluster.g_query.get_epoch()
        clusterlib_utils.save_ledger_state(
            cluster_obj=cluster,
            state_name=f"{temp_template}_{this_epoch}",
        )

        _save_all_metrics(temp_template=f"{temp_template}_{this_epoch}_before_refresh")
        _save_all_period_info(temp_template=f"{temp_template}_{this_epoch}_before_refresh")

        # Refresh opcerts on pools that are not supposed to expire
        cluster.wait_for_epoch(epoch_no=1)
        _refresh_opcerts()

        expected_err_regexes = ["KESKeyAlreadyPoisoned", "KESCouldNotEvolve"]
        # Ignore expected errors in bft1 node log file, as bft1 opcert will not get refreshed
        logfiles.add_ignore_rule(
            files_glob="bft1.stdout",
            regex="|".join(expected_err_regexes),
            ignore_file_id=worker_id,
        )
        logfiles.add_ignore_rule(
            files_glob="bft1.stdout",
            regex="TraceNoLedgerView",
            ignore_file_id=worker_id,
        )
        # Ignore `TraceNoLedgerView` in pool1 node log file as well
        logfiles.add_ignore_rule(
            files_glob="pool1.stdout",
            regex="TraceNoLedgerView",
            ignore_file_id=worker_id,
        )
        # Search for expected errors only in log file corresponding to pool with expired KES
        expected_errors: list[tuple[str, str]] = [
            (f"{expire_node_name}.stdout", err) for err in expected_err_regexes
        ]

        with logfiles.expect_errors(expected_errors, worker_id=worker_id):
            LOGGER.info(
                f"{datetime.datetime.now(tz=datetime.timezone.utc)}: "
                f"Waiting for slot no {expire_slot} for KES expiration."
            )
            cluster.wait_for_slot(slot=expire_slot)
            LOGGER.info(
                f"{datetime.datetime.now(tz=datetime.timezone.utc)}: "
                f"KES expired (?); tip: '{cluster.g_query.get_tip()}'."
            )

            _save_all_metrics(temp_template=f"{temp_template}_after_expire")
            _save_all_period_info(temp_template=f"{temp_template}_after_expire")

            # Prevent KES from expiring before reaching next epoch on pools that are not
            # supposed to expire.
            _refresh_opcerts()

            this_epoch, is_minting = _check_block_production(
                cluster_obj=cluster,
                temp_template=temp_template,
                pool_id_dec=expire_pool_id_dec,
                in_epoch=cluster.g_query.get_epoch() + 1,
            )

            _save_all_metrics(temp_template=f"{temp_template}_{this_epoch}_before_refresh")
            _save_all_period_info(temp_template=f"{temp_template}_{this_epoch}_before_refresh")

            # Check that the expired pool is not minting any blocks
            assert not is_minting, (
                f"The pool '{expire_pool_name}' has minted blocks in epoch {this_epoch}"
            )

            # Refresh opcerts one more time on pools that are not supposed to expire
            refreshed_nodes_kes_period = _refresh_opcerts()

            this_epoch = cluster.g_query.get_epoch()
            _save_all_metrics(temp_template=f"{temp_template}_{this_epoch}_after_refresh")
            _save_all_period_info(temp_template=f"{temp_template}_{this_epoch}_after_refresh")

            kes_period_info_errors_list = _check_kes_period_info(
                refreshed_nodes_kes_period=refreshed_nodes_kes_period
            )

            LOGGER.info(
                f"{datetime.datetime.now(tz=datetime.timezone.utc)}: "
                "Waiting 90 secs to make sure the expected errors make it to log files."
            )
            time.sleep(90)

        kes.finish_on_errors(errors=kes_period_info_errors_list)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.order(6)
    @pytest.mark.long
    def test_opcert_invalid_kes_period(
        self,
        cluster_singleton: clusterlib.ClusterLib,
        cluster_manager: cluster_management.ClusterManager,
    ):
        """Start a stake pool with an operational certificate created with invalid `--kes-period`.

        * generate new operational certificate with `--kes-period` in the future
        * restart the node with the new operational certificate
        * check that the pool is not minting any blocks
        * if network era > Alonzo

            - generate new operational certificate with valid `--kes-period`, but counter value +2
              from last used operational certificate
            - restart the node
            - check that the pool is not minting any blocks

        * generate new operational certificate with valid `--kes-period` and restart the node
        * check that the pool is minting blocks again
        """
        __: tp.Any  # mypy workaround
        kes_period_info_errors_list = []
        pool_name = cluster_management.Resources.POOL_FOR_OFFLINE
        pool_num = int(pool_name.replace("node-pool", ""))
        node_name = pool_name.replace("node-", "")
        cluster = cluster_singleton

        temp_template = common.get_test_id(cluster)
        pool_rec = cluster_manager.cache.addrs_data[pool_name]

        node_cold = pool_rec["cold_key_pair"]
        pool_id = cluster.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
        pool_id_dec = helpers.decode_bech32(pool_id)

        opcert_file: pl.Path = pool_rec["pool_operational_cert"]
        cold_counter_file: pl.Path = pool_rec["cold_key_pair"].counter_file

        expected_errors = [
            (f"{node_name}.stdout", "PraosCannotForgeKeyNotUsableYet"),
        ]

        expected_errors.append((f"{node_name}.stdout", "CounterOverIncrementedOCERT"))
        # In Babbage we get `CounterOverIncrementedOCERT` error if counter for new opcert
        # is not exactly +1 from last used opcert. We'll backup the original counter
        # file so we can use it for issuing next valid opcert.
        cold_counter_file_orig = pl.Path(
            f"{cold_counter_file.stem}_orig{cold_counter_file.suffix}"
        ).resolve()
        shutil.copy(cold_counter_file, cold_counter_file_orig)

        logfiles.add_ignore_rule(
            files_glob="*.stdout",
            regex="MuxBearerClosed|CounterOverIncrementedOCERT",
            ignore_file_id=cluster_manager.worker_id,
        )

        # Generate new operational certificate with `--kes-period` in the future
        invalid_kes_period = cluster.g_query.get_kes_period() + 100
        invalid_opcert_file = cluster.g_node.gen_node_operational_cert(
            node_name=f"{node_name}_invalid_opcert_file",
            kes_vkey_file=pool_rec["kes_key_pair"].vkey_file,
            cold_skey_file=pool_rec["cold_key_pair"].skey_file,
            cold_counter_file=cold_counter_file,
            kes_period=invalid_kes_period,
        )

        with cluster_manager.respin_on_failure():
            with logfiles.expect_errors(expected_errors, worker_id=cluster_manager.worker_id):
                # Restart the node with the new operational certificate (restart all nodes so
                # the connection is established again)
                shutil.copy(invalid_opcert_file, opcert_file)
                cluster_nodes.restart_all_nodes(delay=5)

                LOGGER.info("Checking blocks production for 4 epochs.")
                this_epoch = cluster.g_query.get_epoch()
                for invalid_opcert_epoch in range(4):
                    this_epoch, is_minting = _check_block_production(
                        cluster_obj=cluster,
                        temp_template=temp_template,
                        pool_id_dec=pool_id_dec,
                        in_epoch=this_epoch + 1,
                    )
                    _save_metrics(pool_num=pool_num, temp_template=f"{temp_template}_{this_epoch}")

                    # Check that the pool is not minting any blocks
                    assert not is_minting, (
                        f"The pool '{pool_name}' has minted blocks in epoch {this_epoch}"
                    )

                    if invalid_opcert_epoch == 1:
                        # Check kes-period-info with operational certificate with
                        # invalid `--kes-period`
                        kes_period_info = cluster.g_query.get_kes_period_info(invalid_opcert_file)
                        with open(
                            f"{temp_template}_kes_period_info_1.json", "w", encoding="utf-8"
                        ) as out_fp:
                            json.dump(kes_period_info, out_fp, indent=2)
                        kes_period_info_errors_list.extend(
                            kes.check_kes_period_info_result(
                                cluster_obj=cluster,
                                kes_output=kes_period_info,
                                expected_scenario=kes.KesScenarios.INVALID_KES_PERIOD,
                                check_id="1",
                                expected_start_kes=invalid_kes_period,
                                pool_num=pool_num,
                            )
                        )

                    # Test the `CounterOverIncrementedOCERT` error - the counter will now be +2 from
                    # last used opcert counter value
                    if invalid_opcert_epoch == 2:
                        overincrement_kes_period = cluster.g_query.get_kes_period()
                        overincrement_opcert_file = cluster.g_node.gen_node_operational_cert(
                            node_name=f"{node_name}_overincrement_opcert_file",
                            kes_vkey_file=pool_rec["kes_key_pair"].vkey_file,
                            cold_skey_file=pool_rec["cold_key_pair"].skey_file,
                            cold_counter_file=cold_counter_file,
                            kes_period=overincrement_kes_period,
                        )
                        # Copy the new certificate and restart the node (restart all nodes so
                        # the connection is established again)
                        shutil.copy(overincrement_opcert_file, opcert_file)
                        cluster_nodes.restart_all_nodes(delay=5)

                        kes_period_info = cluster.g_query.get_kes_period_info(
                            overincrement_opcert_file
                        )
                        with open(
                            f"{temp_template}_kes_period_info_2.json", "w", encoding="utf-8"
                        ) as out_fp:
                            json.dump(kes_period_info, out_fp, indent=2)
                        kes_period_info_errors_list.extend(
                            kes.check_kes_period_info_result(
                                cluster_obj=cluster,
                                kes_output=kes_period_info,
                                expected_scenario=kes.KesScenarios.INVALID_COUNTERS,
                                check_id="2",
                                expected_start_kes=overincrement_kes_period,
                                pool_num=pool_num,
                            )
                        )

                    if invalid_opcert_epoch == 3:
                        # Check kes-period-info with operational certificate with
                        # invalid kes-period
                        kes_period_info = cluster.g_query.get_kes_period_info(invalid_opcert_file)
                        with open(
                            f"{temp_template}_kes_period_info_3.json", "w", encoding="utf-8"
                        ) as out_fp:
                            json.dump(kes_period_info, out_fp, indent=2)
                        kes_period_info_errors_list.extend(
                            kes.check_kes_period_info_result(
                                cluster_obj=cluster,
                                kes_output=kes_period_info,
                                expected_scenario=kes.KesScenarios.INVALID_KES_PERIOD,
                                check_id="3",
                                expected_start_kes=invalid_kes_period,
                                pool_num=pool_num,
                            )
                        )

            # In Babbage we'll use the original counter for issuing new valid opcert so the counter
            # value of new valid opcert equals to counter value of the original opcert +1
            shutil.copy(cold_counter_file_orig, cold_counter_file)

            # Generate new operational certificate with valid `--kes-period`
            valid_kes_period = cluster.g_query.get_kes_period()
            valid_opcert_file = cluster.g_node.gen_node_operational_cert(
                node_name=f"{node_name}_valid_opcert_file",
                kes_vkey_file=pool_rec["kes_key_pair"].vkey_file,
                cold_skey_file=pool_rec["cold_key_pair"].skey_file,
                cold_counter_file=cold_counter_file,
                kes_period=valid_kes_period,
            )
            # Copy the new certificate and restart the node (restart all nodes so
            # the connection is established again)
            shutil.copy(valid_opcert_file, opcert_file)
            cluster_nodes.restart_all_nodes(delay=5)

            LOGGER.info("Checking blocks production for up to 6 epochs.")
            updated_epoch = cluster.g_query.get_epoch()
            this_epoch = updated_epoch
            for __ in range(6):
                this_epoch, is_minting = _check_block_production(
                    cluster_obj=cluster,
                    temp_template=temp_template,
                    pool_id_dec=pool_id_dec,
                    in_epoch=this_epoch + 1,
                )
                _save_metrics(pool_num=pool_num, temp_template=f"{temp_template}_{this_epoch}")

                # Check that the pool is minting blocks
                if is_minting:
                    break
            else:
                try:
                    common.fail_on_fork(
                        cluster_manager=cluster_manager,
                        cluster_obj=cluster,
                        temp_template=temp_template,
                    )
                except AssertionError as exc:
                    if (
                        "forked blockchain" in str(exc)
                        and VERSIONS.transaction_era >= VERSIONS.ALONZO
                        and not configuration.ENABLE_LEGACY
                    ):
                        pytest.xfail(str(exc))
                    raise

                msg = (
                    f"The pool '{pool_name}' has not minted any blocks since epoch {updated_epoch}."
                )
                raise AssertionError(msg)

        # Check kes-period-info with valid operational certificate
        kes_period_info = cluster.g_query.get_kes_period_info(valid_opcert_file)
        with open(f"{temp_template}_kes_period_info_4.json", "w", encoding="utf-8") as out_fp:
            json.dump(kes_period_info, out_fp, indent=2)
        kes_period_info_errors_list.extend(
            kes.check_kes_period_info_result(
                cluster_obj=cluster,
                kes_output=kes_period_info,
                expected_scenario=kes.KesScenarios.ALL_VALID,
                check_id="4",
                expected_start_kes=valid_kes_period,
                pool_num=pool_num,
            )
        )

        # Check kes-period-info with operational certificate with invalid kes-period
        kes_period_info = cluster.g_query.get_kes_period_info(invalid_opcert_file)
        with open(f"{temp_template}_kes_period_info_5.json", "w", encoding="utf-8") as out_fp:
            json.dump(kes_period_info, out_fp, indent=2)
        kes_period_info_errors_list.extend(
            kes.check_kes_period_info_result(
                cluster_obj=cluster,
                kes_output=kes_period_info,
                expected_scenario=kes.KesScenarios.INVALID_KES_PERIOD,
                check_id="5",
                expected_start_kes=invalid_kes_period,
                pool_num=pool_num,
            )
        )

        kes.finish_on_errors(errors=kes_period_info_errors_list)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.order(7)
    @pytest.mark.long
    def test_update_valid_opcert(
        self,
        cluster_singleton: clusterlib.ClusterLib,
        cluster_manager: cluster_management.ClusterManager,
    ):
        """Update a valid operational certificate with another valid operational certificate.

        * generate new operational certificate with valid `--kes-period`
        * copy new operational certificate to the node
        * stop the node so the corresponding pool is not minting new blocks
        * check `kes-period-info` while the pool is not minting blocks
        * start the node with the new operational certificate
        * check that the pool is minting blocks again
        * check that metrics reported by `kes-period-info` got updated once the pool started
          minting blocks again
        * check `kes-period-info` with the old (replaced) operational certificate
        """
        __: tp.Any  # mypy workaround
        kes_period_info_errors_list = []
        pool_name = cluster_management.Resources.POOL_FOR_OFFLINE
        pool_num = int(pool_name.replace("node-pool", ""))
        node_name = pool_name.replace("node-", "")
        cluster = cluster_singleton

        temp_template = common.get_test_id(cluster)
        pool_rec = cluster_manager.cache.addrs_data[pool_name]

        node_cold = pool_rec["cold_key_pair"]
        pool_id = cluster.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
        pool_id_dec = helpers.decode_bech32(pool_id)

        opcert_file = pool_rec["pool_operational_cert"]
        opcert_file_old = shutil.copy(opcert_file, f"{opcert_file}_old")

        with cluster_manager.respin_on_failure():
            # Generate new operational certificate with valid `--kes-period`
            new_kes_period = cluster.g_query.get_kes_period()
            new_opcert_file = cluster.g_node.gen_node_operational_cert(
                node_name=f"{node_name}_new_opcert_file",
                kes_vkey_file=pool_rec["kes_key_pair"].vkey_file,
                cold_skey_file=pool_rec["cold_key_pair"].skey_file,
                cold_counter_file=pool_rec["cold_key_pair"].counter_file,
                kes_period=new_kes_period,
            )

            # Copy new operational certificate to the node
            logfiles.add_ignore_rule(
                files_glob="*.stdout",
                regex="MuxBearerClosed",
                ignore_file_id=cluster_manager.worker_id,
            )
            shutil.copy(new_opcert_file, opcert_file)

            # Stop the node so the corresponding pool is not minting new blocks
            cluster_nodes.stop_nodes([node_name])

            time.sleep(10)

            # Check kes-period-info while the pool is not minting blocks
            kes_period_info_new = cluster.g_query.get_kes_period_info(opcert_file)
            with open(f"{temp_template}_kes_period_info_1.json", "w", encoding="utf-8") as out_fp:
                json.dump(kes_period_info_new, out_fp, indent=2)
            kes_period_info_errors_list.extend(
                kes.check_kes_period_info_result(
                    cluster_obj=cluster,
                    kes_output=kes_period_info_new,
                    expected_scenario=kes.KesScenarios.ALL_VALID,
                    check_id="1",
                    expected_start_kes=new_kes_period,
                )
            )
            kes_period_info_old = cluster.g_query.get_kes_period_info(opcert_file_old)
            with open(f"{temp_template}_kes_period_info_2.json", "w", encoding="utf-8") as out_fp:
                json.dump(kes_period_info_old, out_fp, indent=2)
            kes_period_info_errors_list.extend(
                kes.check_kes_period_info_result(
                    cluster_obj=cluster,
                    kes_output=kes_period_info_old,
                    expected_scenario=kes.KesScenarios.ALL_VALID,
                    check_id="2",
                )
            )
            new_opcert_num = kes_period_info_new["metrics"][
                "qKesNodeStateOperationalCertificateNumber"
            ]
            old_opcert_num = kes_period_info_old["metrics"][
                "qKesNodeStateOperationalCertificateNumber"
            ]
            if new_opcert_num != old_opcert_num:
                kes_period_info_errors_list.append(
                    f"New and old opcert counters don't match: {new_opcert_num} vs {old_opcert_num}"
                )

            # Start the node with the new operational certificate (restart all nodes so
            # the connection is established again)
            cluster_nodes.restart_all_nodes(delay=5)

            LOGGER.info("Checking blocks production for up to 6 epochs.")
            updated_epoch = cluster.g_query.get_epoch()
            this_epoch = updated_epoch
            for __ in range(6):
                this_epoch, is_minting = _check_block_production(
                    cluster_obj=cluster,
                    temp_template=temp_template,
                    pool_id_dec=pool_id_dec,
                    in_epoch=this_epoch + 1,
                )
                _save_metrics(pool_num=pool_num, temp_template=f"{temp_template}_{this_epoch}")

                # Check that the pool is minting blocks
                if is_minting:
                    break
            else:
                try:
                    common.fail_on_fork(
                        cluster_manager=cluster_manager,
                        cluster_obj=cluster,
                        temp_template=temp_template,
                    )
                except AssertionError as exc:
                    if (
                        "forked blockchain" in str(exc)
                        and VERSIONS.transaction_era >= VERSIONS.ALONZO
                        and not configuration.ENABLE_LEGACY
                    ):
                        pytest.xfail(str(exc))
                    raise

                msg = (
                    f"The pool '{pool_name}' has not minted any blocks since epoch {updated_epoch}."
                )
                raise AssertionError(msg)

        # Check that metrics reported by kes-period-info got updated once the pool started
        # minting blocks again
        kes_period_info_updated = cluster.g_query.get_kes_period_info(opcert_file)
        with open(f"{temp_template}_kes_period_info_3.json", "w", encoding="utf-8") as out_fp:
            json.dump(kes_period_info_updated, out_fp, indent=2)
        kes_period_info_errors_list.extend(
            kes.check_kes_period_info_result(
                cluster_obj=cluster,
                kes_output=kes_period_info_updated,
                expected_scenario=kes.KesScenarios.ALL_VALID,
                check_id="3",
                expected_start_kes=new_kes_period,
                pool_num=pool_num,
            )
        )

        updated_opcert_num = kes_period_info_updated["metrics"][
            "qKesNodeStateOperationalCertificateNumber"
        ]
        old_opcert_num = kes_period_info_old["metrics"]["qKesNodeStateOperationalCertificateNumber"]
        if updated_opcert_num == old_opcert_num:
            kes_period_info_errors_list.append(
                f"Both updated and old opcert counters have same value '{old_opcert_num}'"
            )

        # Check kes-period-info with operational certificate with a wrong counter
        kes_period_info_invalid = cluster.g_query.get_kes_period_info(opcert_file_old)
        with open(f"{temp_template}_kes_period_info_4.json", "w", encoding="utf-8") as out_fp:
            json.dump(kes_period_info_invalid, out_fp, indent=2)
        kes_period_info_errors_list.extend(
            kes.check_kes_period_info_result(
                cluster_obj=cluster,
                kes_output=kes_period_info_invalid,
                expected_scenario=kes.KesScenarios.INVALID_COUNTERS,
                check_id="4",
                pool_num=pool_num,
            )
        )

        kes.finish_on_errors(errors=kes_period_info_errors_list)

    @allure.link(helpers.get_vcs_link())
    def test_no_kes_period_arg(
        self,
        cluster: clusterlib.ClusterLib,
        cluster_manager: cluster_management.ClusterManager,
    ):
        """Try to generate new operational certificate without specifying the `--kes-period`.

        Expect failure.
        """
        pool_name = cluster_management.Resources.POOL2
        pool_rec = cluster_manager.cache.addrs_data[pool_name]

        temp_template = common.get_test_id(cluster)
        out_file = pl.Path(f"{temp_template}_shouldnt_exist.opcert")

        # Try to generate new operational certificate without specifying the `--kes-period`
        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.cli(
                [
                    "node",
                    "issue-op-cert",
                    "--kes-verification-key-file",
                    str(pool_rec["kes_key_pair"].vkey_file),
                    "--cold-signing-key-file",
                    str(pool_rec["cold_key_pair"].skey_file),
                    "--operational-certificate-issue-counter",
                    str(pool_rec["cold_key_pair"].counter_file),
                    "--out-file",
                    str(out_file),
                ]
            )
        assert "Missing: --kes-period NATURAL" in str(excinfo.value)
        assert not out_file.exists(), "New operational certificate was generated"

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    def test_negative_kes_period_arg(
        self,
        cluster: clusterlib.ClusterLib,
        cluster_manager: cluster_management.ClusterManager,
    ):
        """Try to generate new operational certificate with a negative value for `--kes-period`.

        Expect failure.
        """
        common.get_test_id(cluster)

        pool_name = cluster_management.Resources.POOL2
        pool_rec = cluster_manager.cache.addrs_data[pool_name]

        node_name = pool_name.replace("node-", "")

        # Generate new operational certificate with negative value for `--kes-period`
        invalid_kes_period = -100

        try:
            cluster.g_node.gen_node_operational_cert(
                node_name=f"{node_name}_invalid_opcert_file",
                kes_vkey_file=pool_rec["kes_key_pair"].vkey_file,
                cold_skey_file=pool_rec["cold_key_pair"].skey_file,
                cold_counter_file=pool_rec["cold_key_pair"].counter_file,
                kes_period=invalid_kes_period,
            )
        except clusterlib.CLIError as exc:
            if "KES_PERIOD must not be less than 0" not in str(exc):
                raise
        else:
            issues.node_3788.finish_test()
