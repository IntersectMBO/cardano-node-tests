"""Tests for operations with stake pools.

* pool registration
* pool deregistration
* pool update
* pool metadata
* pool reregistration
"""

import dataclasses
import json
import logging
import pathlib as pl
import typing as tp

import allure
import hypothesis
import hypothesis.strategies as st
import pytest
import pytest_subtests
from _pytest.fixtures import FixtureRequest
from cardano_clusterlib import clusterlib

from cardano_node_tests.cluster_management import cluster_management
from cardano_node_tests.tests import common
from cardano_node_tests.tests import issues
from cardano_node_tests.utils import cluster_nodes
from cardano_node_tests.utils import clusterlib_utils
from cardano_node_tests.utils import configuration
from cardano_node_tests.utils import dbsync_utils
from cardano_node_tests.utils import helpers
from cardano_node_tests.utils import locking
from cardano_node_tests.utils import smash_utils
from cardano_node_tests.utils import temptools
from cardano_node_tests.utils import tx_view
from cardano_node_tests.utils import web
from cardano_node_tests.utils.versions import VERSIONS

DATA_DIR = pl.Path(__file__).parent / "data"
LOGGER = logging.getLogger(__name__)
DEREG_BUFFER_SEC = 30
TWO_HOURS_SEC = 2 * 60 * 60


@pytest.fixture(scope="module")
def pool_cost_start_cluster() -> pl.Path:
    """Update *minPoolCost* to 500."""
    shared_tmp = temptools.get_pytest_shared_tmp()

    # Need to lock because this same fixture can run on several workers in parallel
    with locking.FileLockIfXdist(f"{shared_tmp}/startup_files_pool_500.lock"):
        destdir = shared_tmp / "startup_files_pool_500"
        destdir.mkdir(exist_ok=True)

        # Return existing script if it is already generated by other worker
        destdir_ls = list(destdir.glob("start-cluster*"))
        if destdir_ls:
            return destdir_ls[0]

        startup_files = cluster_nodes.get_cluster_type().cluster_scripts.copy_scripts_files(
            destdir=destdir
        )
        with open(startup_files.genesis_spec, encoding="utf-8") as fp_in:
            genesis_spec = json.load(fp_in)

        genesis_spec["protocolParams"]["minPoolCost"] = 500

        with open(startup_files.genesis_spec, "w", encoding="utf-8") as fp_out:
            json.dump(genesis_spec, fp_out)

        return startup_files.start_script.parent


def _check_pool(
    cluster_obj: clusterlib.ClusterLib,
    stake_pool_id: str,
    pool_data: clusterlib.PoolData,
):
    """Check and return ledger state of the pool, and optionally also db-sync records."""
    pool_params: dict = cluster_obj.g_query.get_pool_state(stake_pool_id=stake_pool_id).pool_params

    assert pool_params, (
        "The newly created stake pool id is not shown inside the available stake pools;\n"
        f"Pool ID: {stake_pool_id} vs Existing IDs: "
        f"{list(cluster_obj.g_query.get_registered_stake_pools_ledger_state())}"
    )
    assert not clusterlib_utils.check_pool_data(
        pool_params=pool_params, pool_creation_data=pool_data
    )

    # Check pool data in db-sync if available
    dbsync_utils.check_pool_data(ledger_pool_data=pool_params, pool_id=stake_pool_id)


def _check_staking(
    pool_owners: list[clusterlib.PoolUser],
    cluster_obj: clusterlib.ClusterLib,
    stake_pool_id: str,
):
    """Check that staking was correctly setup."""
    pool_params: dict = cluster_obj.g_query.get_pool_state(stake_pool_id=stake_pool_id).pool_params

    for i in range(4):
        if i > 0:
            cluster_obj.wait_for_new_block(new_blocks=2)
        if stake_pool_id in cluster_obj.g_query.get_stake_distribution():
            break
    else:
        msg = f"Stake pool `{stake_pool_id}` not registered."
        raise AssertionError(msg)

    for owner in pool_owners:
        stake_addr_info = cluster_obj.g_query.get_stake_addr_info(owner.stake.address)

        # Check that the stake address was delegated
        assert stake_addr_info.delegation, f"Stake address was not delegated yet: {stake_addr_info}"
        assert stake_pool_id == stake_addr_info.delegation, "Stake address delegated to wrong pool"

        assert (
            # Strip 'e0' from the beginning of the address hash
            helpers.decode_bech32(stake_addr_info.address)[2:]
            in helpers.get_pool_param("owners", pool_params=pool_params)
        ), "'owner' value is different than expected"


def _register_stake_pool_w_build(
    cluster_obj: clusterlib.ClusterLib,
    pool_data: clusterlib.PoolData,
    pool_owners: list[clusterlib.PoolUser],
    vrf_vkey_file: clusterlib.FileType,
    cold_key_pair: clusterlib.ColdKeyPair,
    tx_name: str,
    build_method: str,
    reward_account_vkey_file: clusterlib.FileType | None = None,
    deposit: int | None = None,
    destination_dir: clusterlib.FileType = ".",
) -> tuple[pl.Path, clusterlib.TxRawOutput]:
    """Register a stake pool using `transaction build` or `transaction build-estimate`.

    Args:
        build_method: One of `BuildMethods.BUILD` or `BuildMethods.BUILD_EST`.
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_data: A `PoolData` tuple containing info about the stake pool.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        vrf_vkey_file: A path to node VRF vkey file.
        cold_key_pair: A `ColdKeyPair` tuple containing the key pair and the counter.
        tx_name: A name of the transaction.
        reward_account_vkey_file: A path to reward account vkey file (optional).
        deposit: A deposit amount needed by the transaction (optional).
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        Tuple[Path, TxRawOutput]: A tuple with pool registration cert file and transaction
            output details.
    """
    tx_name = f"{tx_name}_reg_pool"
    pool_reg_cert_file = cluster_obj.g_stake_pool.gen_pool_registration_cert(
        pool_data=pool_data,
        vrf_vkey_file=vrf_vkey_file,
        cold_vkey_file=cold_key_pair.vkey_file,
        owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
        reward_account_vkey_file=reward_account_vkey_file,
        destination_dir=destination_dir,
    )

    signing_key_files = [
        *[p.payment.skey_file for p in pool_owners],
        *[p.stake.skey_file for p in pool_owners],
        cold_key_pair.skey_file,
    ]

    tx_files = clusterlib.TxFiles(
        certificate_files=[pool_reg_cert_file],
        signing_key_files=signing_key_files,
    )

    if build_method == clusterlib_utils.BuildMethods.BUILD:
        tx_raw_output = cluster_obj.g_transaction.build_tx(
            src_address=pool_owners[0].payment.address,
            tx_name=tx_name,
            tx_files=tx_files,
            deposit=deposit,
            fee_buffer=2_000_000,
            witness_override=len(pool_owners) * 3,
            destination_dir=destination_dir,
        )
    elif build_method == clusterlib_utils.BuildMethods.BUILD_EST:
        tx_raw_output = cluster_obj.g_transaction.build_estimate_tx(
            src_address=pool_owners[0].payment.address,
            tx_name=tx_name,
            tx_files=tx_files,
            deposit=deposit,
            fee_buffer=2_000_000,
            witness_count_add=len(signing_key_files),
            destination_dir=destination_dir,
        )
    else:
        msg = f"Unsupported build method: {build_method}"
        raise ValueError(msg)

    # Sign incrementally (both flows allow this check)
    tx_signed = cluster_obj.g_transaction.sign_tx(
        tx_body_file=tx_raw_output.out_file,
        signing_key_files=signing_key_files[:1],
        tx_name=f"{tx_name}_sign0",
    )
    tx_signed_inc = cluster_obj.g_transaction.sign_tx(
        tx_file=tx_signed,
        signing_key_files=signing_key_files[1:],
        tx_name=f"{tx_name}_sign1",
    )

    cluster_obj.g_transaction.submit_tx(tx_file=tx_signed_inc, txins=tx_raw_output.txins)
    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_reg_cert_file, tx_raw_output


def _create_stake_pool(
    cluster_obj: clusterlib.ClusterLib,
    pool_data: clusterlib.PoolData,
    pool_owners: list[clusterlib.PoolUser],
    tx_name: str,
    build_method: str,
    reward_account_key_pair: clusterlib.KeyPair | clusterlib.AddressRecord | None = None,
    destination_dir: clusterlib.FileType = ".",
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool using a `transaction build` command.

    Args:
        build_method: One of `BuildMethods.BUILD` or `BuildMethods.BUILD_EST`.
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_data: A `PoolData` tuple containing info about the stake pool.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        tx_name: A name of the transaction.
        reward_account_key_pair: A data container containing reward account key pair (optional).
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        PoolCreationOutput: A tuple containing pool creation output.
    """
    # Create the KES key pair
    node_kes = cluster_obj.g_node.gen_kes_key_pair(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(f"KES keys created - {node_kes.vkey_file}; {node_kes.skey_file}")

    # Create the VRF key pair
    node_vrf = cluster_obj.g_node.gen_vrf_key_pair(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(f"VRF keys created - {node_vrf.vkey_file}; {node_vrf.skey_file}")

    # Create the cold key pair and node operational certificate counter
    node_cold = cluster_obj.g_node.gen_cold_key_pair_and_counter(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(
        "Cold keys created and counter created - "
        f"{node_cold.vkey_file}; {node_cold.skey_file}; {node_cold.counter_file}"
    )

    pool_reg_cert_file, tx_raw_output = _register_stake_pool_w_build(
        cluster_obj=cluster_obj,
        pool_data=pool_data,
        pool_owners=pool_owners,
        vrf_vkey_file=node_vrf.vkey_file,
        cold_key_pair=node_cold,
        tx_name=tx_name,
        build_method=build_method,
        reward_account_vkey_file=reward_account_key_pair.vkey_file
        if reward_account_key_pair
        else None,
        destination_dir=destination_dir,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return clusterlib.PoolCreationOutput(
        stake_pool_id=cluster_obj.g_stake_pool.get_stake_pool_id(node_cold.vkey_file),
        vrf_key_pair=node_vrf,
        cold_key_pair=node_cold,
        pool_reg_cert_file=pool_reg_cert_file,
        pool_data=pool_data,
        pool_owners=pool_owners,
        reward_account_key_pair=reward_account_key_pair or pool_owners[0].stake,
        tx_raw_output=tx_raw_output,
        kes_key_pair=node_kes,
    )


def _deregister_stake_pool_w_build(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: list[clusterlib.PoolUser],
    cold_key_pair: clusterlib.ColdKeyPair,
    epoch: int,
    pool_name: str,
    tx_name: str,
    build_method: str = clusterlib_utils.BuildMethods.BUILD,
    destination_dir: clusterlib.FileType = ".",
) -> tuple[pl.Path, clusterlib.TxRawOutput]:
    """Deregister a stake pool.

    Args:
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        cold_key_pair: A `ColdKeyPair` tuple containing the key pair and the counter.
        epoch: An epoch where the update proposal will take effect (optional).
        build_method: One of `BuildMethods.BUILD` or `BuildMethods.BUILD_EST`.
        pool_name: A name of the stake pool.
        tx_name: A name of the transaction.
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        Tuple[Path, TxRawOutput]: A tuple with pool registration cert file and transaction
            output details.
    """
    tx_name = f"{tx_name}_dereg_pool"
    LOGGER.debug(
        f"Deregistering stake pool starting with epoch: {epoch}; "
        f"Current epoch is: {cluster_obj.g_query.get_epoch()}"
    )
    pool_dereg_cert_file = cluster_obj.g_stake_pool.gen_pool_deregistration_cert(
        pool_name=pool_name,
        cold_vkey_file=cold_key_pair.vkey_file,
        epoch=epoch,
        destination_dir=destination_dir,
    )

    # Submit the pool deregistration certificate through a tx
    tx_files = clusterlib.TxFiles(
        certificate_files=[pool_dereg_cert_file],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            cold_key_pair.skey_file,
        ],
    )

    if build_method == clusterlib_utils.BuildMethods.BUILD:
        tx_raw_output = cluster_obj.g_transaction.build_tx(
            src_address=pool_owners[0].payment.address,
            tx_name=tx_name,
            tx_files=tx_files,
            fee_buffer=2_000_000,
            witness_override=len(tx_files.signing_key_files),
            destination_dir=destination_dir,
        )
    elif build_method == clusterlib_utils.BuildMethods.BUILD_EST:
        tx_raw_output = cluster_obj.g_transaction.build_estimate_tx(
            src_address=pool_owners[0].payment.address,
            tx_name=tx_name,
            tx_files=tx_files,
            fee_buffer=2_000_000,
            witness_count_add=len(tx_files.signing_key_files),
            destination_dir=destination_dir,
        )
    else:
        msg = f"Unsupported build method: {build_method}"
        raise ValueError(msg)
    tx_signed = cluster_obj.g_transaction.sign_tx(
        tx_body_file=tx_raw_output.out_file,
        signing_key_files=tx_files.signing_key_files,
        tx_name=tx_name,
    )
    cluster_obj.g_transaction.submit_tx(tx_file=tx_signed, txins=tx_raw_output.txins)

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_dereg_cert_file, tx_raw_output


def _create_register_pool(
    cluster_obj: clusterlib.ClusterLib,
    temp_template: str,
    temp_dir: pl.Path,
    pool_owners: list[clusterlib.PoolUser],
    pool_data: clusterlib.PoolData,
    reward_account_key_pair: clusterlib.KeyPair | clusterlib.AddressRecord | None = None,
    request: FixtureRequest | None = None,
    build_method: str = clusterlib_utils.BuildMethods.BUILD_RAW,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool.

    Common functionality for tests.
    """
    temp_dir = temp_dir.expanduser().resolve()
    temp_template_reg = f"{temp_template}_reg_pool"

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # Create and register pool
    if build_method in (
        clusterlib_utils.BuildMethods.BUILD,
        clusterlib_utils.BuildMethods.BUILD_EST,
    ):
        pool_creation_out = _create_stake_pool(
            cluster_obj=cluster_obj,
            pool_data=pool_data,
            pool_owners=pool_owners,
            tx_name=temp_template_reg,
            build_method=build_method,
            reward_account_key_pair=reward_account_key_pair,
        )
    elif build_method == clusterlib_utils.BuildMethods.BUILD_RAW:
        pool_creation_out = cluster_obj.g_stake_pool.create_stake_pool(
            pool_data=pool_data,
            pool_owners=pool_owners,
            tx_name=temp_template_reg,
            reward_account_key_pair=reward_account_key_pair,
        )
        dbsync_utils.check_tx(
            cluster_obj=cluster_obj, tx_raw_output=pool_creation_out.tx_raw_output
        )
    else:
        msg = f"Unsupported build method: {build_method}"
        raise ValueError(msg)

    # Deregister stake pool
    def _deregister():
        depoch = 1 if cluster_obj.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
        with helpers.change_cwd(temp_dir):
            cluster_obj.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=cluster_obj.g_query.get_epoch() + depoch,
                pool_name=pool_data.pool_name,
                tx_name=f"{temp_template}_cleanup",
            )

    if request is not None:
        request.addfinalizer(_deregister)

    # Check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - cluster_obj.g_query.get_pool_deposit()
        - pool_creation_out.tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # Check that pool was correctly setup
    _check_pool(
        cluster_obj=cluster_obj,
        stake_pool_id=pool_creation_out.stake_pool_id,
        pool_data=pool_data,
    )

    return pool_creation_out


def _create_register_pool_delegate_stake_tx(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: list[clusterlib.PoolUser],
    temp_template: str,
    temp_dir: pl.Path,
    pool_data: clusterlib.PoolData,
    reward_account_key_pair: clusterlib.KeyPair | clusterlib.AddressRecord | None = None,
    request: FixtureRequest | None = None,
    build_method: str = clusterlib_utils.BuildMethods.BUILD_RAW,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool, delegate stake address - all in single TX.

    Common functionality for tests.
    """
    temp_dir = temp_dir.expanduser().resolve()
    temp_template_reg_deleg = f"{temp_template}_reg_pool_deleg"

    # Create node VRF key pair
    node_vrf = cluster_obj.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
    # Create node cold key pair and counter
    node_cold = cluster_obj.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

    # Create stake address registration certs for pool owners
    stake_addr_reg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
            addr_name=f"{temp_template_reg_deleg}_addr{i}",
            deposit_amt=common.get_conway_address_deposit(cluster_obj=cluster_obj),
            stake_vkey_file=p.stake.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    # Create stake address registration cert for reward address
    if reward_account_key_pair:
        stake_addr_reg_cert_files.append(
            cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
                addr_name=f"{temp_template_reg_deleg}_reward_addr",
                deposit_amt=common.get_conway_address_deposit(cluster_obj=cluster_obj),
                stake_vkey_file=reward_account_key_pair.vkey_file,
            )
        )

    # Create stake address delegation certs for pool owners
    stake_addr_deleg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_delegation_cert(
            addr_name=f"{temp_template_reg_deleg}_addr{i}",
            stake_vkey_file=p.stake.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    # Create stake pool registration cert
    pool_reg_cert_file = cluster_obj.g_stake_pool.gen_pool_registration_cert(
        pool_data=pool_data,
        vrf_vkey_file=node_vrf.vkey_file,
        cold_vkey_file=node_cold.vkey_file,
        owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
        reward_account_vkey_file=reward_account_key_pair.vkey_file
        if reward_account_key_pair
        else None,
    )

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # Register and delegate stake address, create and register pool
    reward_account_skey = [reward_account_key_pair.skey_file] if reward_account_key_pair else []
    tx_files = clusterlib.TxFiles(
        certificate_files=[
            pool_reg_cert_file,
            *stake_addr_reg_cert_files,
            *stake_addr_deleg_cert_files,
        ],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            *reward_account_skey,
            node_cold.skey_file,
        ],
    )

    tx_raw_output = clusterlib_utils.build_and_submit_tx(
        cluster_obj=cluster_obj,
        name_template=temp_template_reg_deleg,
        src_address=src_address,
        tx_files=tx_files,
        fee_buffer=4_000_000,
        witness_override=len(pool_owners) * 4,
        witness_count_add=len(pool_owners) * 4,
        build_method=build_method,
    )

    # Deregister stake pool
    def _deregister():
        depoch = 1 if cluster_obj.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
        with helpers.change_cwd(temp_dir):
            cluster_obj.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=node_cold,
                epoch=cluster_obj.g_query.get_epoch() + depoch,
                pool_name=pool_data.pool_name,
                tx_name=f"{temp_template}_cleanup",
            )

    if request is not None:
        request.addfinalizer(_deregister)

    # Check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - len(stake_addr_reg_cert_files) * cluster_obj.g_query.get_address_deposit()
        - cluster_obj.g_query.get_pool_deposit()
        - tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # Check that pool and staking were correctly setup
    stake_pool_id = cluster_obj.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
    _check_pool(cluster_obj=cluster_obj, stake_pool_id=stake_pool_id, pool_data=pool_data)
    _check_staking(
        pool_owners,
        cluster_obj=cluster_obj,
        stake_pool_id=stake_pool_id,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return clusterlib.PoolCreationOutput(
        stake_pool_id=stake_pool_id,
        vrf_key_pair=node_vrf,
        cold_key_pair=node_cold,
        pool_reg_cert_file=pool_reg_cert_file,
        pool_data=pool_data,
        pool_owners=pool_owners,
        reward_account_key_pair=reward_account_key_pair or pool_owners[0].stake,
        tx_raw_output=tx_raw_output,
    )


def _create_register_pool_tx_delegate_stake_tx(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: list[clusterlib.PoolUser],
    temp_template: str,
    temp_dir: pl.Path,
    pool_data: clusterlib.PoolData,
    reward_account_key_pair: clusterlib.KeyPair | clusterlib.AddressRecord | None = None,
    request: FixtureRequest | None = None,
    build_method: str = clusterlib_utils.BuildMethods.BUILD_RAW,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool - first TX; delegate stake address - second TX.

    Common functionality for tests.
    """
    # Create and register pool
    pool_creation_out = _create_register_pool(
        cluster_obj=cluster_obj,
        temp_template=temp_template,
        temp_dir=temp_dir,
        pool_owners=pool_owners,
        pool_data=pool_data,
        reward_account_key_pair=reward_account_key_pair,
        request=request,
        build_method=build_method,
    )

    # Create stake address registration certs for pool owners
    stake_addr_reg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
            addr_name=f"{temp_template}_addr{i}",
            deposit_amt=common.get_conway_address_deposit(cluster_obj=cluster_obj),
            stake_vkey_file=p.stake.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    # Create stake address registration cert for reward address
    if reward_account_key_pair:
        stake_addr_reg_cert_files.append(
            cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
                addr_name=f"{temp_template}_reward_addr",
                deposit_amt=common.get_conway_address_deposit(cluster_obj=cluster_obj),
                stake_vkey_file=reward_account_key_pair.vkey_file,
            )
        )

    # Create stake address delegation certs for pool users
    stake_addr_deleg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_delegation_cert(
            addr_name=f"{temp_template}_addr{i}",
            stake_vkey_file=p.stake.vkey_file,
            cold_vkey_file=pool_creation_out.cold_key_pair.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # Register and delegate stake addresses
    reward_account_skey = [reward_account_key_pair.skey_file] if reward_account_key_pair else []
    tx_files = clusterlib.TxFiles(
        certificate_files=[*stake_addr_reg_cert_files, *stake_addr_deleg_cert_files],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            *reward_account_skey,
            pool_creation_out.cold_key_pair.skey_file,
        ],
    )

    tx_raw_output = clusterlib_utils.build_and_submit_tx(
        cluster_obj=cluster_obj,
        name_template=f"{temp_template}_reg_deleg",
        src_address=src_address,
        tx_files=tx_files,
        fee_buffer=2_000_000,
        witness_count_add=len(tx_files.signing_key_files),
        witness_override=len(pool_owners) * 3,
        build_method=build_method,
    )

    # Check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - len(stake_addr_reg_cert_files) * cluster_obj.g_query.get_address_deposit()
        - tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # Check that staking was correctly setup
    _check_staking(
        pool_owners,
        cluster_obj=cluster_obj,
        stake_pool_id=pool_creation_out.stake_pool_id,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_creation_out


class TestStakePool:
    """General tests for stake pools."""

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.testnets
    @pytest.mark.smoke
    @pytest.mark.dbsync
    def test_stake_pool_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        request: FixtureRequest,
        build_method: str,
    ):
        """Create and register a stake pool with metadata.

        Check that pool was registered and stake address delegated.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_name = "test_stake_pool_metadata"
        pool_metadata_file = DATA_DIR / "pool_metadata.json"

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.2,
            pool_metadata_url="https://tinyurl.com/yvkfs7pr",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=3,
            fund_idx=[0],
            amount=900_000_000,
        )

        # Register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_data=pool_data,
            request=request,
            build_method=build_method,
        )

        # Check `transaction view` command
        tx_view.check_tx_view(cluster_obj=cluster, tx_raw_output=pool_creation_out.tx_raw_output)

        # Check dbsync `PoolOfflineData` table
        if configuration.HAS_DBSYNC:
            pool_params = cluster.g_query.get_pool_state(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params

            def _query_func():
                dbsync_utils.check_pool_off_chain_data(
                    ledger_pool_data=pool_params, pool_id=pool_creation_out.stake_pool_id
                )

            dbsync_utils.retry_query(query_func=_query_func, timeout=360)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.testnets
    @pytest.mark.smoke
    @pytest.mark.dbsync
    @pytest.mark.smash
    def test_stake_pool_not_avail_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        request: FixtureRequest,
    ):
        """Create and register a stake pool with metadata file not available.

        Check that pool was registered and stake address delegated.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{pool_name}_registration_metadata.json", content=pool_metadata
        )
        pool_metadata_url = "https://www.where_metadata_file_is_located.com"
        pool_metadata_hash = cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.2,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=pool_metadata_hash,
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=1,
            fund_idx=[0],
            amount=900_000_000,
        )

        # Register pool and delegate stake address
        pool_creation_out = _create_register_pool_tx_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_data=pool_data,
            request=request,
            build_method=clusterlib_utils.BuildMethods.BUILD_RAW,
        )

        # Check dbsync `PoolOffChainFetchError` table
        # since the metadata url is invalid the dbsync dedicated thread will not fetch the data
        # and will insert an error on the specific table
        # https://github.com/IntersectMBO/cardano-db-sync/blob/master/doc/pool-offchain-data.md
        if configuration.HAS_DBSYNC:
            pool_params = cluster.g_query.get_pool_state(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params

            def _query_func():
                dbsync_utils.check_pool_off_chain_fetch_error(
                    ledger_pool_data=pool_params, pool_id=pool_creation_out.stake_pool_id
                )

            dbsync_utils.retry_query(query_func=_query_func, timeout=360)
            smash_utils.check_smash_pool_errors(
                pool_id=pool_creation_out.stake_pool_id, pool_metadata_hash=pool_metadata_hash
            )

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.parametrize("no_of_addr", (1, 3))
    @pytest.mark.testnets
    @pytest.mark.smoke
    @pytest.mark.dbsync
    def test_create_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        no_of_addr: int,
        request: FixtureRequest,
        build_method: str,
    ):
        """Create and register a stake pool (without metadata).

        Check that pool was registered.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=12_345,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.123,
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=no_of_addr,
            fund_idx=[0],
            amount=900_000_000,
        )

        # Register pool
        _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            build_method=build_method,
        )

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.testnets
    @pytest.mark.dbsync
    @pytest.mark.smash
    def test_deregister_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        build_method: str,
    ):
        """Deregister stake pool.

        * deregister stake pool
        * check that the stake addresses are no longer delegated
        * check that the pool deposit was returned to reward account
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = pl.Path(
            helpers.write_json(
                out_file=f"{pool_name}_registration_metadata.json", content=pool_metadata
            )
        )
        pool_metadata_url = web.publish(file_path=pool_metadata_file)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=3,
            fund_idx=[0],
            amount=900_000_000,
        )

        # Register pool and delegate stake address
        pool_creation_out = _create_register_pool_tx_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_data=pool_data,
            build_method=build_method,
        )

        pool_owner = pool_owners[0]
        src_register_balance = cluster.g_query.get_address_balance(pool_owner.payment.address)

        src_register_reward = cluster.g_query.get_stake_addr_info(
            pool_owner.stake.address
        ).reward_account_balance

        # Deregister stake pool
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 1
        if build_method in (
            clusterlib_utils.BuildMethods.BUILD,
            clusterlib_utils.BuildMethods.BUILD_EST,
        ):
            __, tx_raw_output = _deregister_stake_pool_w_build(
                cluster_obj=cluster,
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
                build_method=build_method,  # pass through the method
            )
        else:
            __, tx_raw_output = cluster.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

        assert (
            cluster.g_query.get_pool_state(stake_pool_id=pool_creation_out.stake_pool_id).retiring
            == depoch
        )

        # Check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(pool_owner.payment.address)
            == src_register_balance - tx_raw_output.fee
        )

        if cluster.epoch_length_sec <= TWO_HOURS_SEC:
            # Check that the pool was deregistered
            cluster.wait_for_epoch(epoch_no=depoch, padding_seconds=5)
            assert not (
                cluster.g_query.get_pool_state(
                    stake_pool_id=pool_creation_out.stake_pool_id
                ).pool_params
            ), f"The pool {pool_creation_out.stake_pool_id} was not deregistered"

            # Check that the stake addresses are no longer delegated
            for owner_rec in pool_owners:
                stake_addr_info = cluster.g_query.get_stake_addr_info(owner_rec.stake.address)
                assert not stake_addr_info.delegation, (
                    f"Stake address is still delegated: {stake_addr_info}"
                )

            # Check that the pool deposit was returned to reward account
            assert (
                cluster.g_query.get_stake_addr_info(pool_owner.stake.address).reward_account_balance
                == src_register_reward + cluster.g_query.get_pool_deposit()
            )

            dbsync_utils.check_pool_deregistration(
                pool_id=pool_creation_out.stake_pool_id, retiring_epoch=depoch
            )
            smash_utils.check_smash_pool_retired(pool_id=pool_creation_out.stake_pool_id)

        # Check `transaction view` command
        tx_view.check_tx_view(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.testnets
    @pytest.mark.dbsync
    def test_reregister_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: pl.Path,
        request: FixtureRequest,
    ):
        """Reregister stake pool.

        * deregister stake pool
        * check that the stake addresses are no longer delegated
        * reregister the pool by resubmitting the pool registration certificate
        * delegate stake address to pool again (the address is already registered)
        * check that pool was correctly setup
        * check that the stake addresses were delegated
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        if cluster.epoch_length_sec > TWO_HOURS_SEC:
            pytest.skip(
                "Testnet epoch is longer than 2 hours "
                f"(epoch length: {cluster.epoch_length_sec / 60 / 60} hours)"
            )

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = pl.Path(
            helpers.write_json(
                out_file=f"{pool_name}_registration_metadata.json", content=pool_metadata
            )
        )
        pool_metadata_url = web.publish(file_path=pool_metadata_file)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=1,
            fund_idx=[0],
            amount=1_500_000_000,
        )

        # Register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_data=pool_data,
        )

        # Deregister stake pool
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 1
        cluster.g_stake_pool.deregister_stake_pool(
            pool_owners=pool_owners,
            cold_key_pair=pool_creation_out.cold_key_pair,
            epoch=depoch,
            pool_name=pool_data.pool_name,
            tx_name=temp_template,
        )
        assert (
            cluster.g_query.get_pool_state(stake_pool_id=pool_creation_out.stake_pool_id).retiring
            == depoch
        )

        # Check that the pool was deregistered
        cluster.wait_for_epoch(epoch_no=depoch, padding_seconds=5)
        assert not (
            cluster.g_query.get_pool_state(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params
        ), f"The pool {pool_creation_out.stake_pool_id} was not deregistered"

        dbsync_utils.check_pool_deregistration(
            pool_id=pool_creation_out.stake_pool_id, retiring_epoch=depoch
        )

        # Check that the stake addresses are no longer delegated
        for owner_rec in pool_owners:
            stake_addr_info = cluster.g_query.get_stake_addr_info(owner_rec.stake.address)
            assert not stake_addr_info.delegation, (
                f"Stake address is still delegated: {stake_addr_info}"
            )

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # Reregister the pool by resubmitting the pool registration certificate,
        # delegate stake address to pool again (the address is already registered)
        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_creation_out.pool_reg_cert_file,
                *list(testfile_temp_dir.glob(f"{temp_template}*_stake_deleg.cert")),
            ],
            signing_key_files=pool_creation_out.tx_raw_output.tx_files.signing_key_files,
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=src_address, tx_name=f"{temp_template}_rereg", tx_files=tx_files
        )

        # Deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=pool_creation_out.cold_key_pair,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=f"{temp_template}_cleanup",
                )

        request.addfinalizer(_deregister)

        # Check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(src_address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), (
            f"Incorrect balance for source address `{src_address}` "
            f"({src_init_balance}, {tx_raw_output.fee}, {cluster.g_query.get_pool_deposit()})"
        )

        # Check that the stake addresses were delegated
        _check_staking(
            pool_owners=pool_owners,
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
        )

        # Check that pool was correctly setup
        _check_pool(
            cluster_obj=cluster, stake_pool_id=pool_creation_out.stake_pool_id, pool_data=pool_data
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.order(7)
    @pytest.mark.long
    @pytest.mark.testnets
    @pytest.mark.dbsync
    def test_cancel_stake_pool_deregistration(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: pl.Path,
        request: FixtureRequest,
    ):
        """Reregister a stake pool that is in course of being retired.

        * deregister stake pool in epoch + 2
        * reregister the pool by resubmitting the pool registration certificate
        * delegate stake address to pool again (the address is already registered)
        * check that no additional pool deposit was used
        * check that pool is still correctly setup
        * check that the stake addresses is still delegated
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        if cluster.epoch_length_sec > TWO_HOURS_SEC:
            pytest.skip(
                "Testnet epoch is longer than 2 hours "
                f"(epoch length: {cluster.epoch_length_sec / 60 / 60} hours)"
            )

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = pl.Path(
            helpers.write_json(
                out_file=f"{pool_name}_registration_metadata.json", content=pool_metadata
            )
        )
        pool_metadata_url = web.publish(file_path=pool_metadata_file)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=1,
            fund_idx=[0],
            amount=1_500_000_000,
        )

        # Register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_data=pool_data,
        )

        # Deregister stake pool in epoch + 2
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 2
        cluster.g_stake_pool.deregister_stake_pool(
            pool_owners=pool_owners,
            cold_key_pair=pool_creation_out.cold_key_pair,
            epoch=depoch,
            pool_name=pool_data.pool_name,
            tx_name=temp_template,
        )
        assert (
            cluster.g_query.get_pool_state(stake_pool_id=pool_creation_out.stake_pool_id).retiring
            == depoch
        )

        cluster.wait_for_epoch(epoch_no=depoch - 1, padding_seconds=5)

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # Reregister the pool by resubmitting the pool registration certificate,
        # delegate stake address to pool again (the address is already registered)
        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_creation_out.pool_reg_cert_file,
                *list(testfile_temp_dir.glob(f"{temp_template}*_stake_deleg.cert")),
            ],
            signing_key_files=pool_creation_out.tx_raw_output.tx_files.signing_key_files,
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=src_address,
            tx_name=f"{temp_template}_rereg_pool",
            tx_files=tx_files,
            deposit=0,  # no additional deposit, the pool is already registered
        )

        # Deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=pool_creation_out.cold_key_pair,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=f"{temp_template}_cleanup",
                )

        request.addfinalizer(_deregister)

        # Check that the balance for source address was correctly updated
        # and no additional pool deposit was used
        assert (
            cluster.g_query.get_address_balance(src_address) == src_init_balance - tx_raw_output.fee
        ), f"Incorrect balance for source address `{src_address}`"

        LOGGER.info("Checking for 3 epochs that the stake pool will NOT get deregistered.")
        for __ in range(3):
            cluster.wait_for_new_epoch(padding_seconds=10)
            if not cluster.g_query.get_pool_state(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params:
                msg = "Pool `{pool_creation_out.stake_pool_id}` got deregistered."
                raise AssertionError(msg)

        # Check that pool is still correctly setup
        _check_pool(
            cluster_obj=cluster, stake_pool_id=pool_creation_out.stake_pool_id, pool_data=pool_data
        )

        # Check that the stake address is still delegated
        _check_staking(
            pool_owners=pool_owners,
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.testnets
    @pytest.mark.dbsync
    def test_update_stake_pool_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        build_method: str,
        request: FixtureRequest,
    ):
        """Update stake pool metadata.

        * register pool
        * update the pool metadata by resubmitting the pool registration certificate
        * check that the pool metadata hash was correctly updated on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"
        no_of_addr = 3

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = pl.Path(
            helpers.write_json(out_file=f"{pool_name}_reg_metadata.json", content=pool_metadata)
        )
        pool_metadata_url = web.publish(file_path=pool_metadata_file)

        pool_metadata_updated = {
            "name": f"{pool_name}_U",
            "description": "pool description update",
            "ticker": "QA22",
            "homepage": "www.qa22.com",
        }
        pool_metadata_updated_file = pl.Path(
            helpers.write_json(
                out_file=f"{pool_name}_reg_metadata_updtd.json",
                content=pool_metadata_updated,
            )
        )
        pool_metadata_updated_url = web.publish(file_path=pool_metadata_updated_file)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=4567,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        pool_data_updated = dataclasses.replace(
            pool_data,
            pool_metadata_url=pool_metadata_updated_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(
                pool_metadata_updated_file
            ),
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=no_of_addr,
            fund_idx=[0],
            amount=900_000_000 * no_of_addr,
        )

        # Register pool
        pool_creation_out = _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            build_method=build_method,
        )

        # Make sure the update doesn't happen close to epoch boundary
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=10, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        update_epoch = cluster.g_query.get_epoch()

        # Update the pool metadata by resubmitting the pool registration certificate
        if build_method in (
            clusterlib_utils.BuildMethods.BUILD,
            clusterlib_utils.BuildMethods.BUILD_EST,
        ):
            _register_stake_pool_w_build(
                cluster_obj=cluster,
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=f"{temp_template}_rereg",
                deposit=0,
                build_method=build_method,
            )
        elif build_method == clusterlib_utils.BuildMethods.BUILD_RAW:
            __, tx_raw_output = cluster.g_stake_pool.register_stake_pool(
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=f"{temp_template}_rereg",
                deposit=0,  # no additional deposit, the pool is already registered
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)
        else:
            msg = f"Unsupported build method: {build_method}"
            raise ValueError(msg)

        # Check that pool is going to be updated with correct data
        pool_state = cluster.g_query.get_pool_state(stake_pool_id=pool_creation_out.stake_pool_id)
        has_issue_5365 = pool_state.future_pool_params == pool_state.pool_params
        if not has_issue_5365:
            assert not clusterlib_utils.check_pool_data(
                pool_params=pool_state.future_pool_params, pool_creation_data=pool_data_updated
            )

        if cluster.epoch_length_sec <= TWO_HOURS_SEC:
            cluster.wait_for_epoch(epoch_no=update_epoch + 1, padding_seconds=5)

            # Check that the pool metadata hash was correctly updated on chain
            _check_pool(
                cluster_obj=cluster,
                stake_pool_id=pool_creation_out.stake_pool_id,
                pool_data=pool_data_updated,
            )

        if has_issue_5365:
            issues.ledger_5365.finish_test()

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.testnets
    @pytest.mark.dbsync
    def test_update_stake_pool_parameters(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        build_method: str,
        request: FixtureRequest,
    ):
        """Update stake pool parameters.

        * register pool
        * update the pool parameters by resubmitting the pool registration certificate
        * check that the pool parameters were correctly updated on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"
        no_of_addr = 2

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = pl.Path(
            helpers.write_json(
                out_file=f"{pool_name}_registration_metadata.json", content=pool_metadata
            )
        )
        pool_metadata_url = web.publish(file_path=pool_metadata_file)

        min_pool_cost = cluster.g_query.get_protocol_params().get("minPoolCost", 500)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=4_567,
            pool_cost=min_pool_cost,
            pool_margin=0.01,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        pool_data_updated = dataclasses.replace(
            pool_data, pool_pledge=1, pool_cost=min_pool_cost + 1_000_000, pool_margin=0.9
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=no_of_addr,
            fund_idx=[0],
            amount=900_000_000 * no_of_addr,
        )

        # Register pool
        pool_creation_out = _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=pl.Path(),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            build_method=build_method,
        )

        # Make sure the update doesn't happen close to epoch boundary
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=10, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        update_epoch = cluster.g_query.get_epoch()

        # Update the pool parameters by resubmitting the pool registration certificate
        if build_method in (
            clusterlib_utils.BuildMethods.BUILD,
            clusterlib_utils.BuildMethods.BUILD_EST,
        ):
            _register_stake_pool_w_build(
                cluster_obj=cluster,
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=f"{temp_template}_rereg",
                deposit=0,
                build_method=build_method,
            )
        elif build_method == clusterlib_utils.BuildMethods.BUILD_RAW:
            __, tx_raw_output = cluster.g_stake_pool.register_stake_pool(
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=f"{temp_template}_rereg",
                deposit=0,  # no additional deposit, the pool is already registered
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)
        else:
            msg = f"Unsupported build method: {build_method}"
            raise ValueError(msg)

        # Check that pool is going to be updated with correct data
        pool_state = cluster.g_query.get_pool_state(stake_pool_id=pool_creation_out.stake_pool_id)
        has_issue_5365 = pool_state.future_pool_params == pool_state.pool_params
        if not has_issue_5365:
            assert not clusterlib_utils.check_pool_data(
                pool_params=pool_state.future_pool_params, pool_creation_data=pool_data_updated
            )

        if cluster.epoch_length_sec <= TWO_HOURS_SEC:
            cluster.wait_for_epoch(epoch_no=update_epoch + 1, padding_seconds=5)

            # Check that the pool parameters were correctly updated on chain
            _check_pool(
                cluster_obj=cluster,
                stake_pool_id=pool_creation_out.stake_pool_id,
                pool_data=pool_data_updated,
            )

        if has_issue_5365:
            issues.ledger_5365.finish_test()

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.testnets
    @pytest.mark.smoke
    @pytest.mark.dbsync
    def test_sign_in_multiple_stages(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: pl.Path,
        request: FixtureRequest,
    ):
        """Create and register a stake pool with TX signed in multiple stages.

        * create stake pool registration cert
        * create witness file for each signing key
        * sign TX using witness files
        * create and register pool
        * check that the pool was correctly registered on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=5,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
        )

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=2,
            fund_idx=[0],
            amount=900_000_000,
        )

        # Create node VRF key pair
        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        # Create node cold key pair and counter
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        # Create stake pool registration cert
        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
        )

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # Keys to sign the TX with
        witness_skeys = (
            pool_owners[0].payment.skey_file,
            pool_owners[1].payment.skey_file,
            pool_owners[0].stake.skey_file,
            pool_owners[1].stake.skey_file,
            node_cold.skey_file,
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_reg_cert_file,
            ],
        )

        fee = cluster.g_transaction.calculate_tx_fee(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            witness_count_add=len(witness_skeys),
        )

        tx_raw_output = cluster.g_transaction.build_raw_tx(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            fee=fee,
        )

        # Create witness file for each signing key
        witness_files = [
            cluster.g_transaction.witness_tx(
                tx_body_file=tx_raw_output.out_file,
                witness_name=f"{temp_template}_skey{idx}",
                signing_key_files=[skey],
            )
            for idx, skey in enumerate(witness_skeys)
        ]

        # Sign TX using witness files
        tx_witnessed_file = cluster.g_transaction.assemble_tx(
            tx_body_file=tx_raw_output.out_file, witness_files=witness_files, tx_name=temp_template
        )
        # Create and register pool
        cluster.g_transaction.submit_tx(tx_file=tx_witnessed_file, txins=tx_raw_output.txins)

        # Deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=node_cold,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=f"{temp_template}_cleanup",
                )

        request.addfinalizer(_deregister)

        # Check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(src_address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), f"Incorrect balance for source address `{src_address}`"

        cluster.wait_for_block(2)

        # Check that the pool was correctly registered on chain
        stake_pool_id = cluster.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
        _check_pool(
            cluster_obj=cluster,
            stake_pool_id=stake_pool_id,
            pool_data=pool_data,
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.order(7)
    @pytest.mark.long
    @pytest.mark.testnets
    @pytest.mark.dbsync
    def test_pool_registration_deregistration(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
    ):
        """Send both pool registration and deregistration certificates in single TX.

        * create pool registration cert
        * create pool deregistration cert
        * register and deregister stake pool in single TX
        * check that the pool deposit was NOT returned to reward account as the reward address
          is not registered (deposit is lost)
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=5,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
        )

        # Create pool owners
        pool_owner = common.get_pool_user(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            amount=900_000_000,
        )

        src_init_balance = cluster.g_query.get_address_balance(pool_owner.payment.address)
        src_init_reward = cluster.g_query.get_stake_addr_info(
            pool_owner.stake.address
        ).reward_account_balance

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        # Create pool registration cert
        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_owner.stake.vkey_file],
        )

        # Make sure we have enough time to finish the deregistration in one epoch
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        dereg_epoch = cluster.g_query.get_epoch()

        # Create pool deregistration cert
        pool_dereg_cert_file = cluster.g_stake_pool.gen_pool_deregistration_cert(
            pool_name=pool_data.pool_name,
            cold_vkey_file=node_cold.vkey_file,
            epoch=cluster.g_query.get_epoch() + 1,
        )

        # Register and deregister stake pool in single TX
        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file, pool_dereg_cert_file],
            signing_key_files=[
                pool_owner.payment.skey_file,
                pool_owner.stake.skey_file,
                node_cold.skey_file,
            ],
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=pool_owner.payment.address,
            tx_name=f"{temp_template}_conflicting_certs",
            tx_files=tx_files,
        )

        # Check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(pool_owner.payment.address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), f"Incorrect balance for source address `{pool_owner.payment.address}`"

        if cluster.epoch_length_sec <= TWO_HOURS_SEC:
            # Check that the pool deposit was NOT returned to reward account as the reward address
            # is not registered (deposit is lost).
            cluster.wait_for_epoch(epoch_no=dereg_epoch + 3, padding_seconds=30)
            assert (
                cluster.g_query.get_stake_addr_info(pool_owner.stake.address).reward_account_balance
                == src_init_reward
            )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)


# It takes long time to setup the cluster instance (when starting from Byron).
# We mark the tests as "long" and set the highest priority, so the setup is done at the
# beginning of the testrun, instead of needing to respin a cluster that is already running.
@common.ORDER5_BYRON
@common.LONG_BYRON
class TestPoolCost:
    """Tests for stake pool cost."""

    @pytest.fixture
    def cluster_mincost(
        self, cluster_manager: cluster_management.ClusterManager, pool_cost_start_cluster: pl.Path
    ) -> clusterlib.ClusterLib:
        return cluster_manager.get(
            mark="minPoolCost",
            lock_resources=[cluster_management.Resources.CLUSTER],
            prio=True,
            cleanup=True,
            scriptsdir=pool_cost_start_cluster,
        )

    @pytest.fixture
    def pool_owners_pbt(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster_mincost: clusterlib.ClusterLib,
    ):
        """Create pool owners for property-based test."""
        cluster = cluster_mincost
        temp_template = common.get_test_id(cluster)

        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=1,
            fund_idx=[0],
            amount=900_000_000,
        )
        return pool_owners

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_cost=st.integers(max_value=499))  # minPoolCost is now 500
    @common.hypothesis_settings()
    def test_stake_pool_low_cost(
        self,
        cluster_mincost: clusterlib.ClusterLib,
        pool_owners_pbt: list[clusterlib.PoolUser],
        pool_cost: int,
    ):
        """Try to create and register a stake pool with pool cost lower than *minPoolCost*.

        Expect failure. Property-based test.
        """
        cluster = cluster_mincost
        rand_str = common.unique_time_str()

        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=12_345,
            pool_cost=pool_cost,
            pool_margin=0.123,
        )

        # Register pool, expect failure
        with pytest.raises(clusterlib.CLIError) as excinfo:
            _create_register_pool(
                cluster_obj=cluster,
                temp_template=temp_template,
                temp_dir=pl.Path(),
                pool_owners=pool_owners_pbt,
                pool_data=pool_data,
            )

        # Check that it failed in an expected way
        err = str(excinfo.value)
        if pool_cost < 0:
            assert "--pool-cost: Failed reading" in err or "expecting digit" in err
        else:
            assert "StakePoolCostTooLowPOOL" in err

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.dbsync
    def test_stake_pool_cost(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster_mincost: clusterlib.ClusterLib,
        subtests: pytest_subtests.SubTests,
        request: FixtureRequest,
    ):
        """Create and register a stake pool with *pool cost* >= *minPoolCost*."""
        cluster = cluster_mincost
        temp_template = common.get_test_id(cluster)

        def _subtest(pool_cost: int) -> None:
            rand_str = clusterlib.get_rand_str(4)
            name_template = f"{temp_template}_{rand_str}"

            pool_data = clusterlib.PoolData(
                pool_name=f"pool_{rand_str}",
                pool_pledge=12_345,
                pool_cost=pool_cost,
                pool_margin=0.123,
            )

            # Create pool owners
            pool_owners = common.get_pool_users(
                name_template=name_template,
                cluster_manager=cluster_manager,
                cluster_obj=cluster,
                num=1,
                fund_idx=[0],
                amount=900_000_000,
            )

            # Register pool
            _create_register_pool(
                cluster_obj=cluster,
                temp_template=name_template,
                temp_dir=pl.Path(),
                pool_owners=pool_owners,
                pool_data=pool_data,
                request=request,
            )

        for pc in (500, 9_999_999):
            with subtests.test(pool_cost=pc):
                _subtest(pc)


class TestNegative:
    """Stake pool tests that are expected to fail."""

    @pytest.fixture
    def pool_users(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
    ) -> list[clusterlib.PoolUser]:
        """Create pool users."""
        created_users = common.get_pool_users(
            name_template=common.get_test_id(cluster),
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=2,
            fund_idx=[0],
            caching_key=helpers.get_current_line_str(),
            amount=600_000_000,
        )
        return created_users

    @pytest.fixture
    def pool_data(self) -> clusterlib.PoolData:
        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{clusterlib.get_rand_str(4)}",
            pool_pledge=5,
            pool_cost=500_000_000,
            pool_margin=0.01,
        )
        return pool_data

    @pytest.fixture
    def gen_pool_registration_cert_data(
        self,
        cluster: clusterlib.ClusterLib,
    ) -> tuple[str, str, clusterlib.KeyPair, clusterlib.ColdKeyPair]:
        rand_str = clusterlib.get_rand_str(3)
        pool_name = f"pool_{rand_str}"

        pool_metadata = {
            "name": pool_name,
            "description": "cardano-node-tests E2E tests",
            "ticker": f"IO{rand_str}",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file="hypothesis_metadata_registration_metadata.json", content=pool_metadata
        )
        pool_metadata_hash = cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)

        # Create node VRF key pair
        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_name)
        # Create node cold key pair and counter
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_name)

        return pool_name, pool_metadata_hash, node_vrf, node_cold

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_registration_cert_wrong_vrf(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong VRF key.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.skey_file,  # skey instead of vkey
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
            )
        assert "Expected: VrfVerificationKey_PraosVRF" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_registration_cert_wrong_cold(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong Cold vkey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.skey_file,  # skey instead of vkey
                owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
            )
        err_msg = str(excinfo.value)
        assert ": StakePoolVerificationKey" in err_msg, err_msg

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_registration_cert_wrong_stake(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong stake vkey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[pool_users[0].stake.skey_file],  # skey instead of vkey
            )
        assert "Expected: StakeVerificationKeyShelley" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_registration_missing_cold_skey(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to register pool using transaction with missing Cold skey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file],
            signing_key_files=[
                pool_users[0].payment.skey_file,
                # Missing node_cold.skey_file
            ],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_transaction.send_tx(
                src_address=pool_users[0].payment.address,
                tx_name="missing_cold_key",
                tx_files=tx_files,
            )
        assert "MissingVKeyWitnessesUTXOW" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_registration_missing_payment_skey(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to register pool using transaction with missing payment skey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file],
            signing_key_files=[
                # Missing payment skey file
                node_cold.skey_file,
            ],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_transaction.send_tx(
                src_address=pool_users[0].payment.address, tx_name="missing_skey", tx_files=tx_files
            )
        assert "MissingVKeyWitnessesUTXOW" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_BUILD_METHOD_NO_EST
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_pool_deregistration_not_registered(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
        build_method: str,
    ):
        """Try to deregister pool that is not registered.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_dereg_cert_file = cluster.g_stake_pool.gen_pool_deregistration_cert(
            pool_name=pool_data.pool_name,
            cold_vkey_file=node_cold.vkey_file,
            epoch=cluster.g_query.get_epoch() + 2,
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_dereg_cert_file],
            signing_key_files=[pool_users[0].payment.skey_file, node_cold.skey_file],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            clusterlib_utils.build_and_submit_tx(
                cluster_obj=cluster,
                name_template="deregister_unregistered",
                src_address=pool_users[0].payment.address,
                tx_files=tx_files,
                fee_buffer=2_000_000,
                build_method=build_method,
            )

        err_msg = str(excinfo.value)
        assert "StakePoolNotRegisteredOnKeyPOOL" in err_msg, err_msg

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_no_name(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *name* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "name" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_no_description(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *description* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "description" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_no_ticker(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *ticker* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "ticker" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_no_homepage(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *homepage* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "homepage" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_name=st.text(min_size=51))
    @common.hypothesis_settings()
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_long_name(
        self,
        cluster: clusterlib.ClusterLib,
        pool_name: str,
    ):
        """Try to create pool metadata hash when the *name* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": pool_name,
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"name" must have at most 50 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_description=st.text(min_size=256, max_size=1000))
    @common.hypothesis_settings()
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_long_description(
        self,
        cluster: clusterlib.ClusterLib,
        pool_description: str,
    ):
        """Try to create pool metadata hash when the *description* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": pool_description,
            "ticker": "IOG1",
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"description" must have at most 255 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_ticker=st.text())
    @common.hypothesis_settings()
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_long_ticker(
        self,
        cluster: clusterlib.ClusterLib,
        pool_ticker: str,
    ):
        """Try to create pool metadata hash when the *ticker* value is longer than allowed.

        Expect failure. Property-based test.
        """
        hypothesis.assume(not (3 <= len(pool_ticker) <= 5))

        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "ticker": pool_ticker,
            "homepage": "https://github.com/IntersectMBO/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"ticker" must have at least 3 and at most 5 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_homepage=st.text(min_size=425, max_size=1000))
    @common.hypothesis_settings()
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_metadata_long_homepage(
        self,
        cluster: clusterlib.ClusterLib,
        pool_homepage: str,
    ):
        """Try to create pool metadata hash when the *homepage* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "CND",
            "description": "CND",
            "ticker": "CND",
            "homepage": pool_homepage,
        }
        pool_metadata_file = helpers.write_json(
            out_file=f"{temp_template}_registration_metadata.json", content=pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert "Stake pool metadata must consist of at most 512 bytes" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(
        url_part=st.text(alphabet=st.characters(blacklist_categories=["C"]), min_size=89)
    )
    @common.hypothesis_settings(max_examples=500)
    @pytest.mark.smoke
    @pytest.mark.testnets
    def test_stake_pool_long_metadata_url(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: list[clusterlib.PoolUser],
        gen_pool_registration_cert_data: tuple[
            str, str, clusterlib.KeyPair, clusterlib.ColdKeyPair
        ],
        url_part: str,
    ):
        """Try to create pool registration cert when the *metadata-url* is longer than allowed.

        Expect failure. Property-based test.
        """
        common.get_test_id(cluster)

        pool_metadata_url = f"https://gist.githubusercontent.com/{url_part}.json"
        assert len(pool_metadata_url) >= 129

        pool_name, pool_metadata_hash, node_vrf, node_cold = gen_pool_registration_cert_data

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=500_000_000,
            pool_margin=0.2,
            pool_metadata_url=pool_metadata_url,
            pool_metadata_hash=pool_metadata_hash,
        )

        # Create stake pool registration cert
        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[p.stake.vkey_file for p in pool_users],
            )
        err_str = str(excinfo.value)
        assert (
            "option --metadata-url: The provided string must have at most 128 characters" in err_str
            or "invalid url" in err_str
            # In cardano-node <= 10.6.0
            or "option --metadata-url: The provided string must have at most 64 characters"
            in err_str
        )


@pytest.mark.skipif(
    VERSIONS.transaction_era < VERSIONS.CONWAY, reason="runs only with Tx era >= Conway"
)
class TestPoolVoteDeleg:
    """Tests for pool vote delegation to DRep."""

    @pytest.fixture
    def pools(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        request: FixtureRequest,
    ) -> list[clusterlib.PoolCreationOutput]:
        """Create pools for testing vote delegation scenarios."""
        temp_template = common.get_test_id(cluster)
        num_pools = 3

        # Create pool owners
        pool_owners = common.get_pool_users(
            name_template=temp_template,
            cluster_manager=cluster_manager,
            cluster_obj=cluster,
            num=num_pools,
            amount=2_000_000_000,
        )

        pools_out = []
        reward_addresses = []
        delegation_cert_files = []
        for i in range(num_pools):
            rand_str = clusterlib.get_rand_str(4)
            name_template = f"{temp_template}_{rand_str}"

            # Create reward addresses
            reward_addr = cluster.g_stake_address.gen_stake_addr_and_keys(
                name=f"{name_template}_reward_addr"
            )
            reward_addresses.append(reward_addr)

            pool_data = clusterlib.PoolData(
                pool_name=f"pool_{rand_str}",
                pool_pledge=12_345,
                pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
                pool_margin=0.123,
            )

            # Register pool
            pools_out.append(
                _create_register_pool_delegate_stake_tx(
                    cluster_obj=cluster,
                    pool_owners=[pool_owners[i]],
                    temp_template=name_template,
                    temp_dir=pl.Path(),
                    pool_data=pool_data,
                    reward_account_key_pair=reward_addr,
                    request=request,
                )
            )

            # Delegate reward address to a DRep.
            # Delegate stake to pools:
            #  * first reward address is delegated to the first pool,
            #  * second reward address is delegated to the first pool,
            #  * third reward address is not delegated to any pool

            vote_always_abstain = i % 2 == 0

            if i == 2:
                deleg_vote_cert = cluster.g_stake_address.gen_vote_delegation_cert(
                    addr_name=name_template,
                    stake_vkey_file=reward_addr.vkey_file,
                    always_abstain=vote_always_abstain,
                    always_no_confidence=not vote_always_abstain,
                )
            else:
                deleg_vote_cert = cluster.g_stake_address.gen_stake_and_vote_delegation_cert(
                    addr_name=name_template,
                    stake_vkey_file=reward_addr.vkey_file,
                    cold_vkey_file=pools_out[0].cold_key_pair.vkey_file,
                    always_abstain=vote_always_abstain,
                    always_no_confidence=not vote_always_abstain,
                )
            delegation_cert_files.append(deleg_vote_cert)

        # Submit all the delegation certificates
        tx_files = clusterlib.TxFiles(
            certificate_files=delegation_cert_files,
            signing_key_files=[
                pool_owners[0].payment.skey_file,
                *[r.skey_file for r in reward_addresses],
            ],
        )

        pparams = cluster.g_query.get_protocol_params()
        deposit_address_amt = cluster.g_query.get_address_deposit(pparams=pparams)

        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        reg_epoch = cluster.g_query.get_epoch()

        clusterlib_utils.build_and_submit_tx(
            cluster_obj=cluster,
            name_template=f"{temp_template}_delegate_reward_addrs",
            src_address=pool_owners[0].payment.address,
            build_method=clusterlib_utils.BuildMethods.BUILD,
            tx_files=tx_files,
            deposit=deposit_address_amt,
        )
        cluster.wait_for_epoch(epoch_no=reg_epoch + 1, padding_seconds=5)

        return pools_out

    def get_subtests(self) -> tp.Generator[tp.Callable, None, None]:
        """Get pool vote delegation scenarios.

        The scenarios are executed as subtests in the `test_pool_delegation` test.
        """

        def reward_to_owner_pool(
            cluster: clusterlib.ClusterLib, pools: list[clusterlib.PoolCreationOutput]
        ):
            """Check vote delegation if reward address is delegated to the owner pool."""
            assert (
                cluster.g_query.get_spo_stake_distribution(
                    spo_vkey_file=pools[0].cold_key_pair.vkey_file
                )[0].vote_delegation
                == "drep-alwaysAbstain"
            )

        yield reward_to_owner_pool

        def reward_to_other_pool(
            cluster: clusterlib.ClusterLib, pools: list[clusterlib.PoolCreationOutput]
        ):
            """Check vote delegation if reward address is delegated to other pool."""
            assert (
                cluster.g_query.get_spo_stake_distribution(
                    spo_vkey_file=pools[1].cold_key_pair.vkey_file
                )[0].vote_delegation
                == "drep-alwaysNoConfidence"
            )

        yield reward_to_other_pool

        def reward_no_deleg(
            cluster: clusterlib.ClusterLib, pools: list[clusterlib.PoolCreationOutput]
        ):
            """Check vote delegation if reward address is not delegated to any pool."""
            assert (
                cluster.g_query.get_spo_stake_distribution(
                    spo_vkey_file=pools[0].cold_key_pair.vkey_file
                )[0].vote_delegation
                == "drep-alwaysAbstain"
            )

        yield reward_no_deleg

        def all_individual_same(
            cluster: clusterlib.ClusterLib,
            pools: list[clusterlib.PoolCreationOutput],  # noqa: ARG001
        ):
            """Check that data in "all pools" query matches data from indidual pool queries."""
            all_records = cluster.g_query.get_spo_stake_distribution()
            for r in all_records:
                single_rec = cluster.g_query.get_spo_stake_distribution(spo_key_hash=r.spo_vkey_hex)
                assert single_rec[0] == r

        yield all_individual_same

    @allure.link(helpers.get_vcs_link())
    def test_pool_vote_delegation(
        self,
        cluster: clusterlib.ClusterLib,
        pools: list[clusterlib.PoolCreationOutput],
        subtests: pytest_subtests.SubTests,
    ):
        """Test pool vote delegation scenarios."""
        common.get_test_id(cluster)

        for subt in self.get_subtests():
            with subtests.test(scenario=subt.__name__):
                subt(cluster=cluster, pools=pools)

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.smoke
    def test_stake_pool_default_vote(
        self,
        cluster: clusterlib.ClusterLib,
        pools: list[clusterlib.PoolCreationOutput],
    ):
        """Check 'cardano-cli query stake-pool-default-vote' for registered SPOs."""
        for pool in pools:
            result = cluster.g_query.get_stake_pool_default_vote(
                spo_vkey_file=pool.cold_key_pair.vkey_file
            )

            assert isinstance(result, str), "Expected string output from stake-pool-default-vote"
            assert result in {
                "DefaultYes",
                "DefaultNo",
                "DefaultAbstain",
                "DefaultNoConfidence",
            }, f"Unexpected default vote value: {result}"
