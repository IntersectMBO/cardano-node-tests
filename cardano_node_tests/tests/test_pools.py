"""Tests for operations with stake pools.

* pool registration
* pool deregistration
* pool update
* pool metadata
* pool reregistration
"""
# pylint: disable=abstract-class-instantiated
import json
import logging
from pathlib import Path
from typing import List
from typing import Optional
from typing import Tuple

import allure
import hypothesis
import hypothesis.strategies as st
import pytest
from _pytest.fixtures import FixtureRequest
from _pytest.tmpdir import TempPathFactory
from cardano_clusterlib import clusterlib

from cardano_node_tests.cluster_management import cluster_management
from cardano_node_tests.tests import common
from cardano_node_tests.utils import cluster_nodes
from cardano_node_tests.utils import clusterlib_utils
from cardano_node_tests.utils import configuration
from cardano_node_tests.utils import dbsync_utils
from cardano_node_tests.utils import helpers
from cardano_node_tests.utils import locking
from cardano_node_tests.utils import temptools
from cardano_node_tests.utils import tx_view

DATA_DIR = Path(__file__).parent / "data"
LOGGER = logging.getLogger(__name__)
DEREG_BUFFER_SEC = 30


@pytest.fixture(scope="module")
def pool_cost_start_cluster(tmp_path_factory: TempPathFactory) -> Path:
    """Update *minPoolCost* to 500."""
    shared_tmp = temptools.get_pytest_shared_tmp(tmp_path_factory)

    # need to lock because this same fixture can run on several workers in parallel
    with locking.FileLockIfXdist(f"{shared_tmp}/startup_files_pool_500.lock"):
        destdir = shared_tmp / "startup_files_pool_500"
        destdir.mkdir(exist_ok=True)

        # return existing script if it is already generated by other worker
        destdir_ls = list(destdir.glob("start-cluster*"))
        if destdir_ls:
            return destdir_ls[0]

        startup_files = cluster_nodes.get_cluster_type().cluster_scripts.copy_scripts_files(
            destdir=destdir
        )
        with open(startup_files.genesis_spec, encoding="utf-8") as fp_in:
            genesis_spec = json.load(fp_in)

        genesis_spec["protocolParams"]["minPoolCost"] = 500

        with open(startup_files.genesis_spec, "w", encoding="utf-8") as fp_out:
            json.dump(genesis_spec, fp_out)

        return startup_files.start_script


def _check_pool(
    cluster_obj: clusterlib.ClusterLib,
    stake_pool_id: str,
    pool_data: clusterlib.PoolData,
):
    """Check and return ledger state of the pool, and optionally also db-sync records."""
    pool_params: dict = clusterlib_utils.get_pool_state(
        cluster_obj=cluster_obj, pool_id=stake_pool_id
    ).pool_params

    assert pool_params, (
        "The newly created stake pool id is not shown inside the available stake pools;\n"
        f"Pool ID: {stake_pool_id} vs Existing IDs: "
        f"{list(cluster_obj.g_query.get_registered_stake_pools_ledger_state())}"
    )
    assert not clusterlib_utils.check_pool_data(
        pool_params=pool_params, pool_creation_data=pool_data
    )

    # check pool data in db-sync if available
    dbsync_utils.check_pool_data(ledger_pool_data=pool_params, pool_id=stake_pool_id)


def _check_staking(
    pool_owners: List[clusterlib.PoolUser],
    cluster_obj: clusterlib.ClusterLib,
    stake_pool_id: str,
):
    """Check that staking was correctly setup."""
    pool_params: dict = clusterlib_utils.get_pool_state(
        cluster_obj=cluster_obj, pool_id=stake_pool_id
    ).pool_params

    LOGGER.info("Waiting up to 3 full epochs for stake pool to be registered.")
    for i in range(4):
        if i > 0:
            cluster_obj.wait_for_new_epoch(padding_seconds=10)
        if stake_pool_id in cluster_obj.g_query.get_stake_distribution():
            break
    else:
        raise AssertionError(f"Stake pool `{stake_pool_id}` not registered even after 3 epochs.")

    for owner in pool_owners:
        stake_addr_info = cluster_obj.g_query.get_stake_addr_info(owner.stake.address)

        # check that the stake address was delegated
        assert stake_addr_info.delegation, f"Stake address was not delegated yet: {stake_addr_info}"
        assert stake_pool_id == stake_addr_info.delegation, "Stake address delegated to wrong pool"

        assert (
            # strip 'e0' from the beginning of the address hash
            helpers.decode_bech32(stake_addr_info.address)[2:]
            in pool_params["owners"]
        ), "'owner' value is different than expected"


def _register_stake_pool_w_build(
    cluster_obj: clusterlib.ClusterLib,
    pool_data: clusterlib.PoolData,
    pool_owners: List[clusterlib.PoolUser],
    vrf_vkey_file: clusterlib.FileType,
    cold_key_pair: clusterlib.ColdKeyPair,
    tx_name: str,
    reward_account_vkey_file: Optional[clusterlib.FileType] = None,
    deposit: Optional[int] = None,
    destination_dir: clusterlib.FileType = ".",
) -> Tuple[Path, clusterlib.TxRawOutput]:
    """Register a stake pool using a `transaction build` command.

    Args:
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_data: A `PoolData` tuple containing info about the stake pool.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        vrf_vkey_file: A path to node VRF vkey file.
        cold_key_pair: A `ColdKeyPair` tuple containing the key pair and the counter.
        tx_name: A name of the transaction.
        reward_account_vkey_file: A path to reward account vkey file (optional).
        deposit: A deposit amount needed by the transaction (optional).
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        Tuple[Path, TxRawOutput]: A tuple with pool registration cert file and transaction
            output details.
    """
    tx_name = f"{tx_name}_reg_pool"
    pool_reg_cert_file = cluster_obj.g_stake_pool.gen_pool_registration_cert(
        pool_data=pool_data,
        vrf_vkey_file=vrf_vkey_file,
        cold_vkey_file=cold_key_pair.vkey_file,
        owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
        reward_account_vkey_file=reward_account_vkey_file,
        destination_dir=destination_dir,
    )

    signing_key_files = [
        *[p.payment.skey_file for p in pool_owners],
        *[p.stake.skey_file for p in pool_owners],
        cold_key_pair.skey_file,
    ]

    # submit the pool registration certificate through a tx
    tx_files = clusterlib.TxFiles(
        certificate_files=[pool_reg_cert_file],
        signing_key_files=signing_key_files,
    )

    tx_raw_output = cluster_obj.g_transaction.build_tx(
        src_address=pool_owners[0].payment.address,
        tx_name=tx_name,
        tx_files=tx_files,
        deposit=deposit,
        fee_buffer=2_000_000,
        witness_override=len(pool_owners) * 3,
        destination_dir=destination_dir,
    )
    # sign incrementally (just to check that it works)
    tx_signed = cluster_obj.g_transaction.sign_tx(
        tx_body_file=tx_raw_output.out_file,
        signing_key_files=signing_key_files[:1],
        tx_name=f"{tx_name}_sign0",
    )
    tx_signed_inc = cluster_obj.g_transaction.sign_tx(
        tx_file=tx_signed,
        signing_key_files=signing_key_files[1:],
        tx_name=f"{tx_name}_sign1",
    )
    cluster_obj.g_transaction.submit_tx(tx_file=tx_signed_inc, txins=tx_raw_output.txins)

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_reg_cert_file, tx_raw_output


def _create_stake_pool_w_build(
    cluster_obj: clusterlib.ClusterLib,
    pool_data: clusterlib.PoolData,
    pool_owners: List[clusterlib.PoolUser],
    tx_name: str,
    destination_dir: clusterlib.FileType = ".",
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool using a `transaction build` command.

    Args:
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_data: A `PoolData` tuple containing info about the stake pool.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        tx_name: A name of the transaction.
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        PoolCreationOutput: A tuple containing pool creation output.
    """
    # create the KES key pair
    node_kes = cluster_obj.g_node.gen_kes_key_pair(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(f"KES keys created - {node_kes.vkey_file}; {node_kes.skey_file}")

    # create the VRF key pair
    node_vrf = cluster_obj.g_node.gen_vrf_key_pair(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(f"VRF keys created - {node_vrf.vkey_file}; {node_vrf.skey_file}")

    # create the cold key pair and node operational certificate counter
    node_cold = cluster_obj.g_node.gen_cold_key_pair_and_counter(
        node_name=pool_data.pool_name,
        destination_dir=destination_dir,
    )
    LOGGER.debug(
        "Cold keys created and counter created - "
        f"{node_cold.vkey_file}; {node_cold.skey_file}; {node_cold.counter_file}"
    )

    pool_reg_cert_file, tx_raw_output = _register_stake_pool_w_build(
        cluster_obj=cluster_obj,
        pool_data=pool_data,
        pool_owners=pool_owners,
        vrf_vkey_file=node_vrf.vkey_file,
        cold_key_pair=node_cold,
        tx_name=tx_name,
        destination_dir=destination_dir,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return clusterlib.PoolCreationOutput(
        stake_pool_id=cluster_obj.g_stake_pool.get_stake_pool_id(node_cold.vkey_file),
        vrf_key_pair=node_vrf,
        cold_key_pair=node_cold,
        pool_reg_cert_file=pool_reg_cert_file,
        pool_data=pool_data,
        pool_owners=pool_owners,
        tx_raw_output=tx_raw_output,
        kes_key_pair=node_kes,
    )


def _deregister_stake_pool_w_build(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: List[clusterlib.PoolUser],
    cold_key_pair: clusterlib.ColdKeyPair,
    epoch: int,
    pool_name: str,
    tx_name: str,
    destination_dir: clusterlib.FileType = ".",
) -> Tuple[Path, clusterlib.TxRawOutput]:
    """Deregister a stake pool.

    Args:
        cluster_obj: An instance of `clusterlib.ClusterLib`.
        pool_owners: A list of `PoolUser` structures containing pool user addresses and keys.
        cold_key_pair: A `ColdKeyPair` tuple containing the key pair and the counter.
        epoch: An epoch where the update proposal will take effect (optional).
        pool_name: A name of the stake pool.
        tx_name: A name of the transaction.
        destination_dir: A path to directory for storing artifacts (optional).

    Returns:
        Tuple[Path, TxRawOutput]: A tuple with pool registration cert file and transaction
            output details.
    """
    tx_name = f"{tx_name}_dereg_pool"
    LOGGER.debug(
        f"Deregistering stake pool starting with epoch: {epoch}; "
        f"Current epoch is: {cluster_obj.g_query.get_epoch()}"
    )
    pool_dereg_cert_file = cluster_obj.g_stake_pool.gen_pool_deregistration_cert(
        pool_name=pool_name,
        cold_vkey_file=cold_key_pair.vkey_file,
        epoch=epoch,
        destination_dir=destination_dir,
    )

    # submit the pool deregistration certificate through a tx
    tx_files = clusterlib.TxFiles(
        certificate_files=[pool_dereg_cert_file],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            cold_key_pair.skey_file,
        ],
    )

    tx_raw_output = cluster_obj.g_transaction.build_tx(
        src_address=pool_owners[0].payment.address,
        tx_name=tx_name,
        tx_files=tx_files,
        fee_buffer=2_000_000,
        witness_override=len(pool_owners) * 3,
        destination_dir=destination_dir,
    )
    tx_signed = cluster_obj.g_transaction.sign_tx(
        tx_body_file=tx_raw_output.out_file,
        signing_key_files=tx_files.signing_key_files,
        tx_name=tx_name,
    )
    cluster_obj.g_transaction.submit_tx(tx_file=tx_signed, txins=tx_raw_output.txins)

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_dereg_cert_file, tx_raw_output


def _create_register_pool(
    cluster_obj: clusterlib.ClusterLib,
    temp_template: str,
    temp_dir: Path,
    pool_owners: List[clusterlib.PoolUser],
    pool_data: clusterlib.PoolData,
    request: Optional[FixtureRequest] = None,
    use_build_cmd: bool = False,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool.

    Common functionality for tests.
    """
    temp_dir = temp_dir.expanduser().resolve()

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # create and register pool
    if use_build_cmd:
        pool_creation_out = _create_stake_pool_w_build(
            cluster_obj=cluster_obj,
            pool_data=pool_data,
            pool_owners=pool_owners,
            tx_name=temp_template,
        )
    else:
        pool_creation_out = cluster_obj.g_stake_pool.create_stake_pool(
            pool_data=pool_data, pool_owners=pool_owners, tx_name=temp_template
        )
        dbsync_utils.check_tx(
            cluster_obj=cluster_obj, tx_raw_output=pool_creation_out.tx_raw_output
        )

    # deregister stake pool
    def _deregister():
        depoch = 1 if cluster_obj.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
        with helpers.change_cwd(temp_dir):
            cluster_obj.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=cluster_obj.g_query.get_epoch() + depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
            )

    if request is not None:
        request.addfinalizer(_deregister)

    # check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - cluster_obj.g_query.get_pool_deposit()
        - pool_creation_out.tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # check that pool was correctly setup
    _check_pool(
        cluster_obj=cluster_obj,
        stake_pool_id=pool_creation_out.stake_pool_id,
        pool_data=pool_data,
    )

    return pool_creation_out


def _create_register_pool_delegate_stake_tx(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: List[clusterlib.PoolUser],
    temp_template: str,
    temp_dir: Path,
    pool_data: clusterlib.PoolData,
    request: Optional[FixtureRequest] = None,
    use_build_cmd: bool = False,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool, delegate stake address - all in single TX.

    Common functionality for tests.
    """
    temp_dir = temp_dir.expanduser().resolve()

    # create node VRF key pair
    node_vrf = cluster_obj.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
    # create node cold key pair and counter
    node_cold = cluster_obj.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

    # create stake address registration certs
    stake_addr_reg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
            addr_name=f"{temp_template}_addr{i}", stake_vkey_file=p.stake.vkey_file
        )
        for i, p in enumerate(pool_owners)
    ]

    # create stake address delegation cert
    stake_addr_deleg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_delegation_cert(
            addr_name=f"{temp_template}_addr{i}",
            stake_vkey_file=p.stake.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    # create stake pool registration cert
    pool_reg_cert_file = cluster_obj.g_stake_pool.gen_pool_registration_cert(
        pool_data=pool_data,
        vrf_vkey_file=node_vrf.vkey_file,
        cold_vkey_file=node_cold.vkey_file,
        owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
    )

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # register and delegate stake address, create and register pool
    tx_files = clusterlib.TxFiles(
        certificate_files=[
            pool_reg_cert_file,
            *stake_addr_reg_cert_files,
            *stake_addr_deleg_cert_files,
        ],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            node_cold.skey_file,
        ],
    )

    if use_build_cmd:
        tx_raw_output = cluster_obj.g_transaction.build_tx(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            fee_buffer=2_000_000,
            witness_override=len(pool_owners) * 3,
        )
        tx_signed = cluster_obj.g_transaction.sign_tx(
            tx_body_file=tx_raw_output.out_file,
            signing_key_files=tx_files.signing_key_files,
            tx_name=temp_template,
        )
        cluster_obj.g_transaction.submit_tx(tx_file=tx_signed, txins=tx_raw_output.txins)
    else:
        tx_raw_output = cluster_obj.g_transaction.send_tx(
            src_address=src_address, tx_name=temp_template, tx_files=tx_files
        )

    # deregister stake pool
    def _deregister():
        depoch = 1 if cluster_obj.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
        with helpers.change_cwd(temp_dir):
            cluster_obj.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=node_cold,
                epoch=cluster_obj.g_query.get_epoch() + depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
            )

    if request is not None:
        request.addfinalizer(_deregister)

    # check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - len(pool_owners) * cluster_obj.g_query.get_address_deposit()
        - cluster_obj.g_query.get_pool_deposit()
        - tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # check that pool and staking were correctly setup
    stake_pool_id = cluster_obj.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
    _check_pool(cluster_obj=cluster_obj, stake_pool_id=stake_pool_id, pool_data=pool_data)
    _check_staking(
        pool_owners,
        cluster_obj=cluster_obj,
        stake_pool_id=stake_pool_id,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return clusterlib.PoolCreationOutput(
        stake_pool_id=stake_pool_id,
        vrf_key_pair=node_vrf,
        cold_key_pair=node_cold,
        pool_reg_cert_file=pool_reg_cert_file,
        pool_data=pool_data,
        pool_owners=pool_owners,
        tx_raw_output=tx_raw_output,
    )


def _create_register_pool_tx_delegate_stake_tx(
    cluster_obj: clusterlib.ClusterLib,
    pool_owners: List[clusterlib.PoolUser],
    temp_template: str,
    temp_dir: Path,
    pool_data: clusterlib.PoolData,
    request: Optional[FixtureRequest] = None,
    use_build_cmd: bool = False,
) -> clusterlib.PoolCreationOutput:
    """Create and register a stake pool - first TX; delegate stake address - second TX.

    Common functionality for tests.
    """
    # create and register pool
    pool_creation_out = _create_register_pool(
        cluster_obj=cluster_obj,
        temp_template=temp_template,
        temp_dir=temp_dir,
        pool_owners=pool_owners,
        pool_data=pool_data,
        request=request,
        use_build_cmd=use_build_cmd,
    )

    # create stake address registration certs
    stake_addr_reg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_registration_cert(
            addr_name=f"{temp_template}_addr{i}", stake_vkey_file=p.stake.vkey_file
        )
        for i, p in enumerate(pool_owners)
    ]

    # create stake address delegation cert
    stake_addr_deleg_cert_files = [
        cluster_obj.g_stake_address.gen_stake_addr_delegation_cert(
            addr_name=f"{temp_template}_addr{i}",
            stake_vkey_file=p.stake.vkey_file,
            cold_vkey_file=pool_creation_out.cold_key_pair.vkey_file,
        )
        for i, p in enumerate(pool_owners)
    ]

    src_address = pool_owners[0].payment.address
    src_init_balance = cluster_obj.g_query.get_address_balance(src_address)

    # register and delegate stake address
    tx_files = clusterlib.TxFiles(
        certificate_files=[*stake_addr_reg_cert_files, *stake_addr_deleg_cert_files],
        signing_key_files=[
            *[p.payment.skey_file for p in pool_owners],
            *[p.stake.skey_file for p in pool_owners],
            pool_creation_out.cold_key_pair.skey_file,
        ],
    )

    if use_build_cmd:
        tx_raw_output = cluster_obj.g_transaction.build_tx(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            fee_buffer=2_000_000,
            witness_override=len(pool_owners) * 3,
        )
        tx_signed = cluster_obj.g_transaction.sign_tx(
            tx_body_file=tx_raw_output.out_file,
            signing_key_files=tx_files.signing_key_files,
            tx_name=temp_template,
        )
        cluster_obj.g_transaction.submit_tx(tx_file=tx_signed, txins=tx_raw_output.txins)
    else:
        tx_raw_output = cluster_obj.g_transaction.send_tx(
            src_address=src_address, tx_name=temp_template, tx_files=tx_files
        )

    # check that the balance for source address was correctly updated
    assert (
        cluster_obj.g_query.get_address_balance(src_address)
        == src_init_balance
        - len(pool_owners) * cluster_obj.g_query.get_address_deposit()
        - tx_raw_output.fee
    ), f"Incorrect balance for source address `{src_address}`"

    # check that staking was correctly setup
    _check_staking(
        pool_owners,
        cluster_obj=cluster_obj,
        stake_pool_id=pool_creation_out.stake_pool_id,
    )

    dbsync_utils.check_tx(cluster_obj=cluster_obj, tx_raw_output=tx_raw_output)

    return pool_creation_out


@pytest.mark.order(7)
@pytest.mark.testnets
@pytest.mark.long
@pytest.mark.dbsync
class TestStakePool:
    """General tests for stake pools."""

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    def test_stake_pool_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        request: FixtureRequest,
        use_build_cmd: bool,
    ):
        """Create and register a stake pool with metadata.

        Check that pool was registered and stake address delegated.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{use_build_cmd}"

        pool_name = "test_stake_pool_metadata"
        pool_metadata = {
            "name": "test_stake_pool_metadata",
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.2,
            pool_metadata_url="https://bit.ly/3HvWQAy",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=3,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_data=pool_data,
            request=request,
            use_build_cmd=use_build_cmd,
        )

        # check `transaction view` command
        tx_view.check_tx_view(cluster_obj=cluster, tx_raw_output=pool_creation_out.tx_raw_output)

        # check dbsync `PoolOfflineData` table
        if configuration.HAS_DBSYNC:
            pool_params = cluster.g_query.get_pool_params(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params

            def _query_func():
                dbsync_utils.check_pool_offline_data(
                    ledger_pool_data=pool_params, pool_id=pool_creation_out.stake_pool_id
                )

            dbsync_utils.retry_query(query_func=_query_func, timeout=120)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    def test_stake_pool_not_avail_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        request: FixtureRequest,
        use_build_cmd: bool,
    ):
        """Create and register a stake pool with metadata file not available.

        Check that pool was registered and stake address delegated.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{use_build_cmd}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.2,
            pool_metadata_url="https://www.where_metadata_file_is_located.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=1,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # register pool and delegate stake address
        pool_creation_out = _create_register_pool_tx_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_data=pool_data,
            request=request,
            use_build_cmd=use_build_cmd,
        )

        # check dbsync `PoolOfflineFetchError` table
        # since the metadata url is invalid the dbsync dedicated thread will not fetch the data
        # and will insert an error on the specific table
        # https://github.com/input-output-hk/cardano-db-sync/blob/master/doc/pool-offline-data.md
        if configuration.HAS_DBSYNC:
            pool_params = cluster.g_query.get_pool_params(
                stake_pool_id=pool_creation_out.stake_pool_id
            ).pool_params

            def _query_func():
                dbsync_utils.check_pool_offline_fetch_error(
                    ledger_pool_data=pool_params, pool_id=pool_creation_out.stake_pool_id
                )

            dbsync_utils.retry_query(query_func=_query_func, timeout=120)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    @pytest.mark.parametrize("no_of_addr", (1, 3))
    def test_create_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        no_of_addr: int,
        request: FixtureRequest,
        use_build_cmd: bool,
    ):
        """Create and register a stake pool (without metadata).

        Check that pool was registered.
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{no_of_addr}_{use_build_cmd}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=12_345,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.123,
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=no_of_addr,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # register pool
        _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            use_build_cmd=use_build_cmd,
        )

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    def test_deregister_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        use_build_cmd: bool,
    ):
        """Deregister stake pool.

        * deregister stake pool
        * check that the stake addresses are no longer delegated
        * check that the pool deposit was returned to reward account
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{use_build_cmd}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url="https://www.where_metadata_file_is_located.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=3,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # register pool and delegate stake address
        pool_creation_out = _create_register_pool_tx_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_data=pool_data,
            use_build_cmd=use_build_cmd,
        )

        pool_owner = pool_owners[0]
        src_register_balance = cluster.g_query.get_address_balance(pool_owner.payment.address)

        src_register_reward = cluster.g_query.get_stake_addr_info(
            pool_owner.stake.address
        ).reward_account_balance

        # deregister stake pool
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 1
        if use_build_cmd:
            __, tx_raw_output = _deregister_stake_pool_w_build(
                cluster_obj=cluster,
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
            )
        else:
            __, tx_raw_output = cluster.g_stake_pool.deregister_stake_pool(
                pool_owners=pool_owners,
                cold_key_pair=pool_creation_out.cold_key_pair,
                epoch=depoch,
                pool_name=pool_data.pool_name,
                tx_name=temp_template,
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)
        assert (
            clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).retiring
            == depoch
        )

        # check that the pool was deregistered
        cluster.wait_for_new_epoch()
        assert not (
            clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).pool_params
        ), f"The pool {pool_creation_out.stake_pool_id} was not deregistered"

        # check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(pool_owner.payment.address)
            == src_register_balance - tx_raw_output.fee
        )

        # check that the stake addresses are no longer delegated
        for owner_rec in pool_owners:
            stake_addr_info = cluster.g_query.get_stake_addr_info(owner_rec.stake.address)
            assert (
                not stake_addr_info.delegation
            ), f"Stake address is still delegated: {stake_addr_info}"

        # check that the pool deposit was returned to reward account
        assert (
            cluster.g_query.get_stake_addr_info(pool_owner.stake.address).reward_account_balance
            == src_register_reward + cluster.g_query.get_pool_deposit()
        )

        # check `transaction view` command
        tx_view.check_tx_view(cluster_obj=cluster, tx_raw_output=tx_raw_output)

        dbsync_utils.check_pool_deregistration(
            pool_id=pool_creation_out.stake_pool_id, retiring_epoch=depoch
        )

    @allure.link(helpers.get_vcs_link())
    def test_reregister_stake_pool(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: Path,
        request: FixtureRequest,
    ):
        """Reregister stake pool.

        * deregister stake pool
        * check that the stake addresses are no longer delegated
        * reregister the pool by resubmitting the pool registration certificate
        * delegate stake address to pool again (the address is already registered)
        * check that pool was correctly setup
        * check that the stake addresses were delegated
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url="https://www.where_metadata_file_is_located.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster, name_template=temp_template
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=1_500_000_000,
        )

        # register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_data=pool_data,
        )

        # deregister stake pool
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 1
        cluster.g_stake_pool.deregister_stake_pool(
            pool_owners=pool_owners,
            cold_key_pair=pool_creation_out.cold_key_pair,
            epoch=depoch,
            pool_name=pool_data.pool_name,
            tx_name=temp_template,
        )
        assert (
            clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).retiring
            == depoch
        )

        # check that the pool was deregistered
        cluster.wait_for_new_epoch()
        assert not (
            clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).pool_params
        ), f"The pool {pool_creation_out.stake_pool_id} was not deregistered"

        dbsync_utils.check_pool_deregistration(
            pool_id=pool_creation_out.stake_pool_id, retiring_epoch=depoch
        )

        # check that the stake addresses are no longer delegated
        for owner_rec in pool_owners:
            stake_addr_info = cluster.g_query.get_stake_addr_info(owner_rec.stake.address)
            assert (
                not stake_addr_info.delegation
            ), f"Stake address is still delegated: {stake_addr_info}"

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # reregister the pool by resubmitting the pool registration certificate,
        # delegate stake address to pool again (the address is already registered)
        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_creation_out.pool_reg_cert_file,
                *list(testfile_temp_dir.glob(f"{temp_template}*_stake_deleg.cert")),
            ],
            signing_key_files=pool_creation_out.tx_raw_output.tx_files.signing_key_files,
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=src_address, tx_name=temp_template, tx_files=tx_files
        )

        # deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=pool_creation_out.cold_key_pair,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=temp_template,
                )

        request.addfinalizer(_deregister)

        # check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(src_address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), (
            f"Incorrect balance for source address `{src_address}` "
            f"({src_init_balance}, {tx_raw_output.fee}, {cluster.g_query.get_pool_deposit()})"
        )

        LOGGER.info("Waiting up to 5 full epochs for stake pool to be reregistered.")
        for __ in range(5):
            cluster.wait_for_new_epoch(padding_seconds=10)
            if pool_creation_out.stake_pool_id in cluster.g_query.get_stake_distribution():
                break
        else:
            raise AssertionError(
                f"Stake pool `{pool_creation_out.stake_pool_id}` not registered "
                "even after 5 epochs."
            )
        # check that pool was correctly setup
        _check_pool(
            cluster_obj=cluster, stake_pool_id=pool_creation_out.stake_pool_id, pool_data=pool_data
        )

        # check that the stake addresses were delegated
        _check_staking(
            pool_owners=pool_owners,
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    def test_cancel_stake_pool_deregistration(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: Path,
        request: FixtureRequest,
    ):
        """Reregister a stake pool that is in course of being retired.

        * deregister stake pool in epoch + 2
        * reregister the pool by resubmitting the pool registration certificate
        * delegate stake address to pool again (the address is already registered)
        * check that no additional pool deposit was used
        * check that pool is still correctly setup
        * check that the stake addresses is still delegated
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=222,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.512,
            pool_metadata_url="https://www.where_metadata_file_is_located.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster, name_template=temp_template
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=1_500_000_000,
        )

        # register pool and delegate stake address
        pool_creation_out = _create_register_pool_delegate_stake_tx(
            cluster_obj=cluster,
            pool_owners=pool_owners,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_data=pool_data,
        )

        # deregister stake pool in epoch + 2
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        depoch = cluster.g_query.get_epoch() + 2
        cluster.g_stake_pool.deregister_stake_pool(
            pool_owners=pool_owners,
            cold_key_pair=pool_creation_out.cold_key_pair,
            epoch=depoch,
            pool_name=pool_data.pool_name,
            tx_name=temp_template,
        )
        assert (
            clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).retiring
            == depoch
        )

        cluster.wait_for_new_epoch()

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # reregister the pool by resubmitting the pool registration certificate,
        # delegate stake address to pool again (the address is already registered)
        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_creation_out.pool_reg_cert_file,
                *list(testfile_temp_dir.glob(f"{temp_template}*_stake_deleg.cert")),
            ],
            signing_key_files=pool_creation_out.tx_raw_output.tx_files.signing_key_files,
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            deposit=0,  # no additional deposit, the pool is already registered
        )

        # deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=pool_creation_out.cold_key_pair,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=temp_template,
                )

        request.addfinalizer(_deregister)

        # check that the balance for source address was correctly updated
        # and no additional pool deposit was used
        assert (
            cluster.g_query.get_address_balance(src_address) == src_init_balance - tx_raw_output.fee
        ), f"Incorrect balance for source address `{src_address}`"

        LOGGER.info("Checking for 3 epochs that the stake pool will NOT get deregistered.")
        for __ in range(3):
            cluster.wait_for_new_epoch(padding_seconds=10)
            if not clusterlib_utils.get_pool_state(
                cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
            ).pool_params:
                raise AssertionError("Pool `{pool_creation_out.stake_pool_id}` got deregistered.")

        # check that pool is still correctly setup
        _check_pool(
            cluster_obj=cluster, stake_pool_id=pool_creation_out.stake_pool_id, pool_data=pool_data
        )

        # check that the stake addresses is still delegated
        _check_staking(
            pool_owners=pool_owners,
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    @pytest.mark.dbsync
    def test_update_stake_pool_metadata(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        use_build_cmd: bool,
        request: FixtureRequest,
    ):
        """Update stake pool metadata.

        * register pool
        * update the pool metadata by resubmitting the pool registration certificate
        * check that the pool metadata hash was correctly updated on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{use_build_cmd}"
        no_of_addr = 3

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        pool_metadata_updated = {
            "name": f"{pool_name}_U",
            "description": "pool description update",
            "ticker": "QA22",
            "homepage": "www.qa22.com",
        }
        pool_metadata_updated_file = helpers.write_json(
            f"{pool_name}_registration_metadata_updated.json",
            pool_metadata_updated,
        )

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=4567,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
            pool_metadata_url="https://init_location.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        pool_data_updated = pool_data._replace(
            pool_metadata_url="https://www.updated_location.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(
                pool_metadata_updated_file
            ),
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=no_of_addr,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000 * no_of_addr,
        )

        # register pool
        pool_creation_out = _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            use_build_cmd=use_build_cmd,
        )

        # make sure the update doesn't happen close to epoch boundary
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=10, stop=common.EPOCH_STOP_SEC_BUFFER
        )

        # update the pool metadata by resubmitting the pool registration certificate
        if use_build_cmd:
            _register_stake_pool_w_build(
                cluster_obj=cluster,
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=temp_template,
                deposit=0,  # no additional deposit, the pool is already registered
            )
        else:
            __, tx_raw_output = cluster.g_stake_pool.register_stake_pool(
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=temp_template,
                deposit=0,  # no additional deposit, the pool is already registered
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

        # check that pool is going to be updated with correct data
        future_params = clusterlib_utils.get_pool_state(
            cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
        ).future_pool_params
        assert not clusterlib_utils.check_pool_data(
            pool_params=future_params, pool_creation_data=pool_data_updated
        )

        cluster.wait_for_new_epoch()

        # check that the pool metadata hash was correctly updated on chain
        _check_pool(
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
            pool_data=pool_data_updated,
        )

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    def test_update_stake_pool_parameters(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        use_build_cmd: bool,
        request: FixtureRequest,
    ):
        """Update stake pool parameters.

        * register pool
        * update the pool parameters by resubmitting the pool registration certificate
        * check that the pool parameters were correctly updated on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{use_build_cmd}"
        no_of_addr = 2

        pool_name = f"pool_{rand_str}"
        pool_metadata = {
            "name": pool_name,
            "description": "Shelley QA E2E test Test",
            "ticker": "QA1",
            "homepage": "www.test1.com",
        }
        pool_metadata_file = helpers.write_json(
            f"{pool_name}_registration_metadata.json", pool_metadata
        )

        min_pool_cost = cluster.g_query.get_protocol_params().get("minPoolCost", 500)

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=4_567,
            pool_cost=min_pool_cost,
            pool_margin=0.01,
            pool_metadata_url="https://www.where_metadata_file_is_located.com",
            pool_metadata_hash=cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file),
        )

        pool_data_updated = pool_data._replace(
            pool_pledge=1, pool_cost=min_pool_cost + 1_000_000, pool_margin=0.9
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=no_of_addr,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000 * no_of_addr,
        )

        # register pool
        pool_creation_out = _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
            use_build_cmd=use_build_cmd,
        )

        # make sure the update doesn't happen close to epoch boundary
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=10, stop=common.EPOCH_STOP_SEC_BUFFER
        )

        # update the pool parameters by resubmitting the pool registration certificate
        if use_build_cmd:
            _register_stake_pool_w_build(
                cluster_obj=cluster,
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=temp_template,
                deposit=0,  # no additional deposit, the pool is already registered
            )
        else:
            __, tx_raw_output = cluster.g_stake_pool.register_stake_pool(
                pool_data=pool_data_updated,
                pool_owners=pool_owners,
                vrf_vkey_file=pool_creation_out.vrf_key_pair.vkey_file,
                cold_key_pair=pool_creation_out.cold_key_pair,
                tx_name=temp_template,
                deposit=0,  # no additional deposit, the pool is already registered
            )
            dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

        # check that pool is going to be updated with correct data
        future_params = clusterlib_utils.get_pool_state(
            cluster_obj=cluster, pool_id=pool_creation_out.stake_pool_id
        ).future_pool_params
        assert not clusterlib_utils.check_pool_data(
            pool_params=future_params, pool_creation_data=pool_data_updated
        )

        cluster.wait_for_new_epoch()

        # check that the pool parameters were correctly updated on chain
        _check_pool(
            cluster_obj=cluster,
            stake_pool_id=pool_creation_out.stake_pool_id,
            pool_data=pool_data_updated,
        )

    @allure.link(helpers.get_vcs_link())
    def test_sign_in_multiple_stages(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
        testfile_temp_dir: Path,
        request: FixtureRequest,
    ):
        """Create and register a stake pool with TX signed in multiple stages.

        * create stake pool registration cert
        * create witness file for each signing key
        * sign TX using witness files
        * create and register pool
        * check that the pool was correctly registered on chain
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=5,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=2,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # create node VRF key pair
        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        # create node cold key pair and counter
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        # create stake pool registration cert
        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[p.stake.vkey_file for p in pool_owners],
        )

        src_address = pool_owners[0].payment.address
        src_init_balance = cluster.g_query.get_address_balance(src_address)

        # keys to sign the TX with
        witness_skeys = (
            pool_owners[0].payment.skey_file,
            pool_owners[1].payment.skey_file,
            pool_owners[0].stake.skey_file,
            pool_owners[1].stake.skey_file,
            node_cold.skey_file,
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[
                pool_reg_cert_file,
            ],
        )

        fee = cluster.g_transaction.calculate_tx_fee(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            witness_count_add=len(witness_skeys),
        )

        tx_raw_output = cluster.g_transaction.build_raw_tx(
            src_address=src_address,
            tx_name=temp_template,
            tx_files=tx_files,
            fee=fee,
        )

        # create witness file for each signing key
        witness_files = [
            cluster.g_transaction.witness_tx(
                tx_body_file=tx_raw_output.out_file,
                witness_name=f"{temp_template}_skey{idx}",
                signing_key_files=[skey],
            )
            for idx, skey in enumerate(witness_skeys)
        ]

        # sign TX using witness files
        tx_witnessed_file = cluster.g_transaction.assemble_tx(
            tx_body_file=tx_raw_output.out_file, witness_files=witness_files, tx_name=temp_template
        )
        # create and register pool
        cluster.g_transaction.submit_tx(tx_file=tx_witnessed_file, txins=tx_raw_output.txins)

        # deregister stake pool
        def _deregister():
            depoch = 1 if cluster.time_to_epoch_end() >= DEREG_BUFFER_SEC else 2
            with helpers.change_cwd(testfile_temp_dir):
                cluster.g_stake_pool.deregister_stake_pool(
                    pool_owners=pool_owners,
                    cold_key_pair=node_cold,
                    epoch=cluster.g_query.get_epoch() + depoch,
                    pool_name=pool_data.pool_name,
                    tx_name=temp_template,
                )

        request.addfinalizer(_deregister)

        # check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(src_address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), f"Incorrect balance for source address `{src_address}`"

        cluster.wait_for_new_epoch()

        # check that the pool was correctly registered on chain
        stake_pool_id = cluster.g_stake_pool.get_stake_pool_id(node_cold.vkey_file)
        _check_pool(
            cluster_obj=cluster,
            stake_pool_id=stake_pool_id,
            pool_data=pool_data,
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_deregistration(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
    ):
        """Send both pool registration and deregistration certificates in single TX.

        * create pool registration cert
        * create pool deregistration cert
        * register and deregister stake pool in single TX
        * check that the pool deposit was NOT returned to reward account as the reward address
          is not registered (deposit is lost)
        """
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=5,
            pool_cost=cluster.g_query.get_protocol_params().get("minPoolCost", 500),
            pool_margin=0.01,
        )

        # create pool owners
        pool_owner = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=1,
        )[0]

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owner.payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        src_init_balance = cluster.g_query.get_address_balance(pool_owner.payment.address)
        src_init_reward = cluster.g_query.get_stake_addr_info(
            pool_owner.stake.address
        ).reward_account_balance

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        # create pool registration cert
        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_owner.stake.vkey_file],
        )

        # create pool deregistration cert
        clusterlib_utils.wait_for_epoch_interval(
            cluster_obj=cluster, start=5, stop=common.EPOCH_STOP_SEC_BUFFER
        )
        pool_dereg_cert_file = cluster.g_stake_pool.gen_pool_deregistration_cert(
            pool_name=pool_data.pool_name,
            cold_vkey_file=node_cold.vkey_file,
            epoch=cluster.g_query.get_epoch() + 1,
        )

        # register and deregister stake pool in single TX
        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file, pool_dereg_cert_file],
            signing_key_files=[
                pool_owner.payment.skey_file,
                pool_owner.stake.skey_file,
                node_cold.skey_file,
            ],
        )
        tx_raw_output = cluster.g_transaction.send_tx(
            src_address=pool_owner.payment.address,
            tx_name=f"{temp_template}_conflicting_certs",
            tx_files=tx_files,
        )

        # check that the balance for source address was correctly updated
        assert (
            cluster.g_query.get_address_balance(pool_owner.payment.address)
            == src_init_balance - tx_raw_output.fee - cluster.g_query.get_pool_deposit()
        ), f"Incorrect balance for source address `{pool_owner.payment.address}`"

        # check that the pool deposit was NOT returned to reward account as the reward address
        # is not registered (deposit is lost)
        cluster.wait_for_new_epoch(3, padding_seconds=30)
        assert (
            cluster.g_query.get_stake_addr_info(pool_owner.stake.address).reward_account_balance
            == src_init_reward
        )

        dbsync_utils.check_tx(cluster_obj=cluster, tx_raw_output=tx_raw_output)


@pytest.mark.order(5)
@pytest.mark.long
@pytest.mark.xdist_group(name="minPoolCost")
class TestPoolCost:
    """Tests for stake pool cost."""

    @pytest.fixture
    def cluster_mincost(
        self, cluster_manager: cluster_management.ClusterManager, pool_cost_start_cluster: Path
    ) -> clusterlib.ClusterLib:
        return cluster_manager.get(
            mark="minPoolCost",
            lock_resources=[cluster_management.Resources.CLUSTER],
            prio=True,
            cleanup=True,
            start_cmd=str(pool_cost_start_cluster),
        )

    @pytest.fixture
    def pool_owners(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster_mincost: clusterlib.ClusterLib,
    ):
        """Create class scoped pool owners."""
        cluster = cluster_mincost

        with cluster_manager.cache_fixture() as fixture_cache:
            if fixture_cache.value:
                return fixture_cache.value  # type: ignore

            temp_template = common.get_test_id(cluster)

            pool_owners = clusterlib_utils.create_pool_users(
                cluster_obj=cluster,
                name_template=temp_template,
                no_of_addr=1,
            )
            fixture_cache.value = pool_owners

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        return pool_owners

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_cost=st.integers(max_value=499))  # minPoolCost is now 500
    @common.hypothesis_settings()
    def test_stake_pool_low_cost(
        self,
        cluster_mincost: clusterlib.ClusterLib,
        pool_owners: List[clusterlib.PoolUser],
        pool_cost: int,
    ):
        """Try to create and register a stake pool with pool cost lower than *minPoolCost*.

        Expect failure. Property-based test.
        """
        cluster = cluster_mincost
        rand_str = common.unique_time_str()

        temp_template = f"{common.get_test_id(cluster)}_{rand_str}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=12_345,
            pool_cost=pool_cost,
            pool_margin=0.123,
        )

        # register pool, expect failure
        with pytest.raises(clusterlib.CLIError) as excinfo:
            _create_register_pool(
                cluster_obj=cluster,
                temp_template=temp_template,
                temp_dir=Path("."),
                pool_owners=pool_owners,
                pool_data=pool_data,
            )

        # check that it failed in an expected way
        err = str(excinfo.value)
        if pool_cost < 0:
            assert "--pool-cost: Failed reading" in err or "expecting digit" in err
        else:
            assert "StakePoolCostTooLowPOOL" in err

    @allure.link(helpers.get_vcs_link())
    @pytest.mark.parametrize("pool_cost", [500, 9_999_999])
    @pytest.mark.dbsync
    def test_stake_pool_cost(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster_mincost: clusterlib.ClusterLib,
        pool_owners: List[clusterlib.PoolUser],
        pool_cost: int,
        request: FixtureRequest,
    ):
        """Create and register a stake pool with *pool cost* >= *minPoolCost*."""
        cluster = cluster_mincost
        rand_str = clusterlib.get_rand_str(4)
        temp_template = f"{common.get_test_id(cluster)}_{rand_str}_{pool_cost}"

        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{rand_str}",
            pool_pledge=12_345,
            pool_cost=pool_cost,
            pool_margin=0.123,
        )

        # create pool owners
        pool_owners = clusterlib_utils.create_pool_users(
            cluster_obj=cluster,
            name_template=temp_template,
            no_of_addr=1,
        )

        # fund source address
        clusterlib_utils.fund_from_faucet(
            pool_owners[0].payment,
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=900_000_000,
        )

        # register pool
        _create_register_pool(
            cluster_obj=cluster,
            temp_template=temp_template,
            temp_dir=Path("."),
            pool_owners=pool_owners,
            pool_data=pool_data,
            request=request,
        )


@pytest.mark.smoke
@pytest.mark.testnets
class TestNegative:
    """Stake pool tests that are expected to fail."""

    @pytest.fixture
    def pool_users(
        self,
        cluster_manager: cluster_management.ClusterManager,
        cluster: clusterlib.ClusterLib,
    ) -> List[clusterlib.PoolUser]:
        """Create pool users."""
        with cluster_manager.cache_fixture() as fixture_cache:
            if fixture_cache.value:
                return fixture_cache.value  # type: ignore

            created_users = clusterlib_utils.create_pool_users(
                cluster_obj=cluster,
                name_template=f"test_negative_ci{cluster_manager.cluster_instance_num}",
                no_of_addr=2,
            )
            fixture_cache.value = created_users

        # fund source addresses
        clusterlib_utils.fund_from_faucet(
            created_users[0],
            cluster_obj=cluster,
            faucet_data=cluster_manager.cache.addrs_data["user1"],
            amount=600_000_000,
        )

        return created_users

    @pytest.fixture
    def pool_data(self) -> clusterlib.PoolData:
        pool_data = clusterlib.PoolData(
            pool_name=f"pool_{clusterlib.get_rand_str(4)}",
            pool_pledge=5,
            pool_cost=500_000_000,
            pool_margin=0.01,
        )
        return pool_data

    @pytest.fixture
    def gen_pool_registration_cert_data(
        self,
        cluster: clusterlib.ClusterLib,
    ) -> Tuple[str, str, clusterlib.KeyPair, clusterlib.ColdKeyPair]:
        rand_str = clusterlib.get_rand_str(3)
        pool_name = f"pool_{rand_str}"

        pool_metadata = {
            "name": pool_name,
            "description": "cardano-node-tests E2E tests",
            "ticker": f"IO{rand_str}",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            "hypothesis_metadata_registration_metadata.json", pool_metadata
        )
        pool_metadata_hash = cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)

        # create node VRF key pair
        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_name)
        # create node cold key pair and counter
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_name)

        return pool_name, pool_metadata_hash, node_vrf, node_cold

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_cert_wrong_vrf(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong VRF key.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.skey_file,  # skey instead of vkey
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
            )
        assert "Expected: VrfVerificationKey_PraosVRF" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_cert_wrong_cold(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong Cold vkey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.skey_file,  # skey instead of vkey
                owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
            )
        assert "Expected: StakePoolVerificationKey" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_cert_wrong_stake(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to generate pool registration certificate using wrong stake vkey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[pool_users[0].stake.skey_file],  # skey instead of vkey
            )
        assert "Expected: StakeVerificationKeyShelley" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_missing_cold_skey(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to register pool using transaction with missing Cold skey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file],
            signing_key_files=[
                pool_users[0].payment.skey_file,
                # missing node_cold.skey_file
            ],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_transaction.send_tx(
                src_address=pool_users[0].payment.address,
                tx_name="missing_cold_key",
                tx_files=tx_files,
            )
        assert "MissingVKeyWitnessesUTXOW" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_pool_registration_missing_payment_skey(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
    ):
        """Try to register pool using transaction with missing payment skey.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_vrf = cluster.g_node.gen_vrf_key_pair(node_name=pool_data.pool_name)
        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_reg_cert_file = cluster.g_stake_pool.gen_pool_registration_cert(
            pool_data=pool_data,
            vrf_vkey_file=node_vrf.vkey_file,
            cold_vkey_file=node_cold.vkey_file,
            owner_stake_vkey_files=[pool_users[0].stake.vkey_file],
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_reg_cert_file],
            signing_key_files=[
                # missing payment skey file
                node_cold.skey_file,
            ],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_transaction.send_tx(
                src_address=pool_users[0].payment.address, tx_name="missing_skey", tx_files=tx_files
            )
        assert "MissingVKeyWitnessesUTXOW" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @common.PARAM_USE_BUILD_CMD
    def test_pool_deregistration_not_registered(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        pool_data: clusterlib.PoolData,
        use_build_cmd: bool,
    ):
        """Try to deregister pool that is not registered.

        Expect failure.
        """
        common.get_test_id(cluster)

        node_cold = cluster.g_node.gen_cold_key_pair_and_counter(node_name=pool_data.pool_name)

        pool_dereg_cert_file = cluster.g_stake_pool.gen_pool_deregistration_cert(
            pool_name=pool_data.pool_name,
            cold_vkey_file=node_cold.vkey_file,
            epoch=cluster.g_query.get_epoch() + 2,
        )

        tx_files = clusterlib.TxFiles(
            certificate_files=[pool_dereg_cert_file],
            signing_key_files=[pool_users[0].payment.skey_file, node_cold.skey_file],
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            if use_build_cmd:
                tx_raw_output = cluster.g_transaction.build_tx(
                    src_address=pool_users[0].payment.address,
                    tx_name="deregister_unregistered",
                    tx_files=tx_files,
                    fee_buffer=2_000_000,
                )
                tx_signed = cluster.g_transaction.sign_tx(
                    tx_body_file=tx_raw_output.out_file,
                    signing_key_files=tx_files.signing_key_files,
                    tx_name="deregister_unregistered",
                )
                cluster.g_transaction.submit_tx(tx_file=tx_signed, txins=tx_raw_output.txins)
            else:
                cluster.g_transaction.send_tx(
                    src_address=pool_users[0].payment.address,
                    tx_name="deregister_unregistered",
                    tx_files=tx_files,
                )
        assert "StakePoolNotRegisteredOnKeyPOOL" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_stake_pool_metadata_no_name(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *name* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "name" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_stake_pool_metadata_no_description(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *description* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "description" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_stake_pool_metadata_no_ticker(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *ticker* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "ticker" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    def test_stake_pool_metadata_no_homepage(
        self,
        cluster: clusterlib.ClusterLib,
    ):
        """Try to create pool metadata hash when missing the *homepage* key.

        Expect failure.
        """
        temp_template = common.get_test_id(cluster)

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert 'key "homepage" not found' in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_name=st.text(min_size=51))
    @common.hypothesis_settings()
    def test_stake_pool_metadata_long_name(
        self,
        cluster: clusterlib.ClusterLib,
        pool_name: str,
    ):
        """Try to create pool metadata hash when the *name* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": pool_name,
            "description": "cardano-node-tests E2E tests",
            "ticker": "IOG1",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"name" must have at most 50 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_description=st.text(min_size=256))
    @common.hypothesis_settings()
    def test_stake_pool_metadata_long_description(
        self,
        cluster: clusterlib.ClusterLib,
        pool_description: str,
    ):
        """Try to create pool metadata hash when the *description* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": pool_description,
            "ticker": "IOG1",
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"description" must have at most 255 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_ticker=st.text())
    @common.hypothesis_settings()
    def test_stake_pool_metadata_long_ticker(
        self,
        cluster: clusterlib.ClusterLib,
        pool_ticker: str,
    ):
        """Try to create pool metadata hash when the *ticker* value is longer than allowed.

        Expect failure. Property-based test.
        """
        hypothesis.assume(not (3 <= len(pool_ticker) <= 5))

        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "cardano-node-tests",
            "description": "cardano-node-tests E2E tests",
            "ticker": pool_ticker,
            "homepage": "https://github.com/input-output-hk/cardano-node-tests",
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        err_value = str(excinfo.value)
        assert (
            "Stake pool metadata must consist of at most 512 bytes" in err_value
            or '"ticker" must have at least 3 and at most 5 characters' in err_value
        )

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(pool_homepage=st.text(min_size=425))
    @common.hypothesis_settings()
    def test_stake_pool_metadata_long_homepage(
        self,
        cluster: clusterlib.ClusterLib,
        pool_homepage: str,
    ):
        """Try to create pool metadata hash when the *homepage* value is longer than allowed.

        Expect failure. Property-based test.
        """
        temp_template = f"{common.get_test_id(cluster)}_{common.unique_time_str()}"

        pool_metadata = {
            "name": "CND",
            "description": "CND",
            "ticker": "CND",
            "homepage": pool_homepage,
        }
        pool_metadata_file = helpers.write_json(
            f"{temp_template}_registration_metadata.json", pool_metadata
        )

        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_metadata_hash(pool_metadata_file)
        assert "Stake pool metadata must consist of at most 512 bytes" in str(excinfo.value)

    @allure.link(helpers.get_vcs_link())
    @hypothesis.given(
        metadata_url=st.text(alphabet=st.characters(blacklist_categories=["C"]), min_size=25)
    )
    @common.hypothesis_settings()
    def test_stake_pool_long_metadata_url(
        self,
        cluster: clusterlib.ClusterLib,
        pool_users: List[clusterlib.PoolUser],
        gen_pool_registration_cert_data: Tuple[
            str, str, clusterlib.KeyPair, clusterlib.ColdKeyPair
        ],
        metadata_url: str,
    ):
        """Try to create pool registration cert when the *metadata-url* is longer than allowed.

        Expect failure. Property-based test.
        """
        common.get_test_id(cluster)

        pool_name, pool_metadata_hash, node_vrf, node_cold = gen_pool_registration_cert_data

        pool_data = clusterlib.PoolData(
            pool_name=pool_name,
            pool_pledge=1_000,
            pool_cost=500_000_000,
            pool_margin=0.2,
            pool_metadata_url=(f"https://gist.githubusercontent.com/{metadata_url}.json"),
            pool_metadata_hash=pool_metadata_hash,
        )

        # create stake pool registration cert
        with pytest.raises(clusterlib.CLIError) as excinfo:
            cluster.g_stake_pool.gen_pool_registration_cert(
                pool_data=pool_data,
                vrf_vkey_file=node_vrf.vkey_file,
                cold_vkey_file=node_cold.vkey_file,
                owner_stake_vkey_files=[p.stake.vkey_file for p in pool_users],
            )
        assert "option --metadata-url: The provided string must have at most 64 characters" in str(
            excinfo.value
        )
